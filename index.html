<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Popal&#39;s Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="技術之路學習歷程">
<meta property="og:type" content="website">
<meta property="og:title" content="Popal's Blog">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Popal's Blog">
<meta property="og:description" content="技術之路學習歷程">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Popal's Blog">
<meta name="twitter:description" content="技術之路學習歷程">
  
    <link rel="alternate" href="/atom.xml" title="Popal&#39;s Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Popal&#39;s Blog</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">邊做邊學</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="Flux RSS"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Rechercher"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-BigData" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/01/08/BigData/" class="article-date">
  <time datetime="2017-01-08T10:00:00.000Z" itemprop="datePublished">2017-01-08</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/technology/">技術之路</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/01/08/BigData/">Hadoop Cluster相關環境建置筆記(持續更新中)</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
<div id="toc">
  <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#安裝前準備"><span class="toc-text">安裝前準備</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Hadoop-Cluster安裝-2-7-2"><span class="toc-text">Hadoop Cluster安裝(2.7.2)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Spark安裝-2-0-0"><span class="toc-text">Spark安裝(2.0.0)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#MariaDB安裝-10-1-17"><span class="toc-text">MariaDB安裝(10.1.17)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Hive安裝-2-1-1"><span class="toc-text">Hive安裝(2.1.1)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#OOZIE安裝-4-3-0"><span class="toc-text">OOZIE安裝(4.3.0)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Anaconda3安裝-4-2-0-選裝"><span class="toc-text">Anaconda3安裝(4.2.0),選裝</span></a></li></ol>
</div>

        <h3 id="安裝前準備"><a href="#安裝前準備" class="headerlink" title="安裝前準備"></a>安裝前準備</h3><blockquote>
<p>以下步驟在Hadoop cluster下的每台電腦皆要安裝與設定 </p>
<ol>
<li>關閉iptables服務</li>
<li>建立haoop帳號,並visudo給hadoop與Root一樣的設定</li>
<li>ssh-copy-id至每台datanode包含namenode</li>
<li>要能在namenode主機上ssh至各台datanode</li>
<li>hadoop cluster環境上的所有主機,皆需要同步系統時間</li>
<li>安裝JDK</li>
</ol>
</blockquote>
<ol>
<li><p>先使用root登入Linux OS</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div></pre></td><td class="code"><pre><div class="line">##停止iptables服務</div><div class="line">[root@hadoop-master]service iptables stop  #停止iptables服務</div><div class="line">[root@hadoop-master]vi /etc/rc.local</div><div class="line">service iptables stop  #停止iptables服務,存檔後離開</div><div class="line"></div><div class="line">##新增hadoop User</div><div class="line">[root@hadoop-master]adduser hadoop</div><div class="line">[root@hadoop-master]passwd  hadoop</div><div class="line">[root@hadoop-master]visudo</div><div class="line">hadoop	ALL=(ALL) ALL  #加入這一行,存檔後離開</div><div class="line">(以上步驟每台電腦都要做)</div><div class="line"></div><div class="line">[root@hadoop-master]su - hadoop</div><div class="line"></div><div class="line">##ssh 設定</div><div class="line">[hadoop@hadoop-master]ssh-keygen</div><div class="line">[hadoop@hadoop-master]ssh-copy-id hadoop@hadoop-master  ##別忘記自己也要copy</div><div class="line">[hadoop@hadoop-master]ssh-copy-id hadoop@hadoop-slave1  ##有幾台datanode就要做幾次</div><div class="line">[hadoop@hadoop-master]ssh-copy-id hadoop@hadoop-slave2  ##有幾台datanode就要做幾次</div><div class="line"></div><div class="line">##ssh連線測試</div><div class="line">[hadoop@hadoop-master]ssh hadoop-master</div><div class="line">[hadoop@hadoop-master]ssh hadoop-slave1</div><div class="line"></div><div class="line">##系統時間同步</div><div class="line">[hadoop@hadoop-master]sudo date [MMddHHmmYYYY];hwclocl -w</div><div class="line">[hadoop@hadoop-slave1]sudo date [MMddHHmmYYYY];hwclocl -w</div><div class="line">[hadoop@hadoop-slave2]sudo date [MMddHHmmYYYY];hwclocl -w</div><div class="line"></div><div class="line">##建立安裝目錄</div><div class="line">[hadoop@hadoop-master]sudo mkdir -p /bgdt/install_src</div><div class="line">[hadoop@hadoop-master]sudo mkdir -p /bgdt/java</div><div class="line">[hadoop@hadoop-master]sudo chown -R hadoop:hadoop /bgdt</div><div class="line"></div><div class="line">##將相關的安裝檔案上傳到 hadoop-master /bget/install_src目錄下</div><div class="line">使用WinSCP上傳比較方便囉!!!</div><div class="line">jdk-8u101-linux-x64.tar.gz</div><div class="line">hadoop-2.7.2.tar.gz</div><div class="line">spark-2.0.0-bin-hadoop2.7.tgz</div><div class="line">apache-hive-2.1.1-bin.tar.gz</div><div class="line">apache-hive-2.1.1-src.tar.gz</div><div class="line">Anaconda3-4.2.0-Linux-x86_64.sh</div><div class="line">oozie-4.3.0-SNAPSHOT-distro.tar.gz</div><div class="line">mysql-connector-java-5.1.39-bin.jar</div></pre></td></tr></table></figure>
</li>
<li><p>安裝JDK</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">[hadoop@hadoop-master]tar -zxvf /bgdt/jdk-8u101-linux-x64.tar.gz -C /bgdt/java</div><div class="line"></div><div class="line">##修改 ~/.bashrc</div><div class="line">[hadoop@hadoop-master]vi ~/.bshrc</div><div class="line">加入以下兩行</div><div class="line">export JAVA_HOME=/usr/local/jdk1.8.0_101</div><div class="line">export PATH=$JAVA_HOME/bin:$PATH</div><div class="line"></div><div class="line">[hadoop@hadoop-master]source ~/.bashrc</div><div class="line">[hadoop@hadoop-master]java -version</div><div class="line">(以上步驟在每台Datanode上也需要安裝喔!!)</div></pre></td></tr></table></figure>
</li>
</ol>
<h3 id="Hadoop-Cluster安裝-2-7-2"><a href="#Hadoop-Cluster安裝-2-7-2" class="headerlink" title="Hadoop Cluster安裝(2.7.2)"></a>Hadoop Cluster安裝(2.7.2)</h3><blockquote>
<p>以下為簡要安裝說明:</p>
<ol>
<li>下載hadoop-2.7.2.tar.gz檔案,並解壓縮及設定相關環境變數</li>
<li>修改設定檔<blockquote>
<ol>
<li>$HADOOP_HOME/etc/hadoop/core-site.xml</li>
<li>$HADOOP_HOME/etc/hadoop/hdfs-site.xml</li>
<li>$HADOOP_HOME/etc/hadoop/mapred-site.xml</li>
<li>$HADOOP_HOME/etc/hadoop/yarn-site.xml</li>
<li>$HADOOP_HOME/etc/hadoop/slaves</li>
</ol>
</blockquote>
</li>
<li>將檔案傳送到其他Datanode</li>
<li>格式化HDFS系統</li>
<li>start-dfs.sh/start-yarn.sh</li>
<li>Web UI<blockquote>
<ol>
<li><a href="http://hadoop-master:50070" target="_blank" rel="external">http://hadoop-master:50070</a></li>
<li><a href="http://hadoop-master:8088" target="_blank" rel="external">http://hadoop-master:8088</a></li>
</ol>
</blockquote>
</li>
</ol>
</blockquote>
<ol>
<li><p>解壓縮並設定相關環境變數</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">[hadoop@hadoop-master]tar -zxvf /bgdt/hadoop-2.7.2.tar.gz -C /bgdt</div><div class="line">##修改 ~/.bashrc</div><div class="line">[hadoop@hadoop-master]vi ~/.bshrc</div><div class="line">加入以下變數</div><div class="line">export HADOOP_HOME=/bgdt/hadoop-2.7.2</div><div class="line">export HADOOP_CONF_DIR=/bgdt/hadoop-2.7.2/etc/hadoop</div><div class="line"></div><div class="line">export CLASSPATH=$CLASSPATH:$HADOOP_HOME/lib/*:.</div><div class="line">export CLASSPATH=$CLASSPATH:$HADOOP_HOME/share/hadoop/common/*:.</div><div class="line"></div><div class="line">export PATH=$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH</div><div class="line"></div><div class="line">[hadoop@hadoop-master]source ~/.bashrc</div><div class="line">[hadoop@hadoop-master]java -version</div></pre></td></tr></table></figure>
</li>
<li><p>修改設定檔(/bgdt/hadoop-2.7.2/etc/hadoop/core-site.xml)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">&lt;configuration&gt;</div><div class="line">&lt;property&gt;</div><div class="line">   &lt;name&gt;fs.defaultFS&lt;/name&gt;</div><div class="line">   &lt;value&gt;hdfs://hadoop-master:8020&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">   &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</div><div class="line">   &lt;value&gt;file:/usr/local/hadoop-2.7.2/tmp&lt;/value&gt;           </div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">   &lt;name&gt;hadoop.proxyuser.hadoop.hosts&lt;/name&gt;</div><div class="line">   &lt;value&gt;*&lt;/value&gt;    </div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">   &lt;name&gt;hadoop.proxyuser.hadoop.groups&lt;/name&gt;</div><div class="line">   &lt;value&gt;*&lt;/value&gt;    </div><div class="line">&lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
</li>
<li><p>修改設定檔(/bgdt/hadoop-2.7.2/etc/hadoop/hdfs-site.xml)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">&lt;configuration&gt;</div><div class="line">  &lt;property&gt;</div><div class="line">   &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;</div><div class="line">   &lt;value&gt;hadoop-master:50070&lt;/value&gt;</div><div class="line">  &lt;/property&gt;</div><div class="line">  &lt;property&gt;</div><div class="line">   &lt;name&gt;dfs.replication&lt;/name&gt;</div><div class="line">   &lt;value&gt;2&lt;/value&gt;</div><div class="line">  &lt;/property&gt;</div><div class="line">  &lt;property&gt;</div><div class="line">   &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;</div><div class="line">   &lt;value&gt;file:/bgdt/hadoop-2.7.2/tmp/dfs/name&lt;/value&gt;</div><div class="line">  &lt;/property&gt;</div><div class="line">  &lt;property&gt;</div><div class="line">   &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;</div><div class="line">   &lt;value&gt;file:/bgdt/hadoop-2.7.2/tmp/dfs/data&lt;/value&gt;</div><div class="line">  &lt;/property&gt;</div><div class="line">  &lt;property&gt;</div><div class="line">   &lt;name&gt;dfs.block.size&lt;/name&gt;</div><div class="line">   &lt;value&gt;64M&lt;/value&gt;   </div><div class="line">  &lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
</li>
<li><p>修改設定檔(/bgdt/hadoop-2.7.2/etc/hadoop/mapred-site.xml)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">&lt;configuration&gt;</div><div class="line">  &lt;property&gt;</div><div class="line">   &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</div><div class="line">   &lt;value&gt;yarn&lt;/value&gt;</div><div class="line">  &lt;/property&gt;</div><div class="line">  &lt;property&gt;</div><div class="line">   &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;</div><div class="line">   &lt;value&gt;hadoop-master:10020&lt;/value&gt;</div><div class="line">  &lt;/property&gt;</div><div class="line">  &lt;property&gt;</div><div class="line">   &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;</div><div class="line">   &lt;value&gt;hadoop-master:19888&lt;/value&gt;</div><div class="line">  &lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
</li>
<li><p>修改設定檔(/bgdt/hadoop-2.7.2/etc/hadoop/yarn-site.xml)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">&lt;configuration&gt;</div><div class="line">   &lt;property&gt;</div><div class="line">    &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;</div><div class="line">    &lt;value&gt;hadoop-master&lt;/value&gt;</div><div class="line">  &lt;/property&gt;</div><div class="line">   &lt;property&gt;</div><div class="line">    &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</div><div class="line">    &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</div><div class="line">  &lt;/property&gt;</div><div class="line">  &lt;property&gt;</div><div class="line">    &lt;name&gt;yarn.log.server.url&lt;/name&gt;</div><div class="line">    &lt;value&gt;http://hadoop-master:19888/jobhistory/logs&lt;/value&gt;</div><div class="line">  &lt;/property&gt;  </div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
</li>
<li><p>修改設定檔(/bgdt/hadoop-2.7.2/etc/hadoop/slaves)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">hadoop-slave1</div><div class="line">hadoop-slave2</div></pre></td></tr></table></figure>
</li>
<li><p>將檔案分送到其他Datanode</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">##將目錄壓縮</div><div class="line">[hadoop@hadoop-master]tar -zcf /bgdt/hadoop.master.tar.gz /bgdt/hadoop-2.7.2</div><div class="line">[hadoop@hadoop-master]scp /bgdt/hadoop.master.tar.gz hadoop-slave1:/bgdt/install_src</div><div class="line">[hadoop@hadoop-master]scp /bgdt/hadoop.master.tar.gz hadoop-slave2:/bgdt/install_src</div><div class="line"></div><div class="line">##各個Datanode將Hadoop解壓縮至/bgdt,解完後設定相關Haoop變數如第一大項</div></pre></td></tr></table></figure>
</li>
<li><p>格式化HDFS系統</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">[hadoop@hadoop-master]hadoop namenode -format</div><div class="line">[hadoop@hadoop-master]hadoop dfsadmin -report</div></pre></td></tr></table></figure>
</li>
<li><p>啟動dfs與yarn</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">[hadoop@hadoop-master]start-dfs.sh</div><div class="line">[hadoop@hadoop-master]start-yarn.sh</div></pre></td></tr></table></figure>
</li>
<li><p>HDFS WebUI(因為後來系統從做,所以主機名稱略有不同)Web UI port:50070<br><img src="/images/dfs_2.jpg" alt=""></p>
</li>
</ol>
<h3 id="Spark安裝-2-0-0"><a href="#Spark安裝-2-0-0" class="headerlink" title="Spark安裝(2.0.0)"></a>Spark安裝(2.0.0)</h3><ol>
<li><p><a href="https://http://spark.apache.org/downloads.html" target="_blank" rel="external">Download spark 2.0.0安裝程式</a><br><img src="/images/spark_1.jpg" alt=""><br>下載後會產生一個 “spark-2.0.0-bin-hadoop2.7.tgz”檔案<br>或使用wget下載,下載前請先確定是否可以連網路囉!!</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">wget -P /bgdt/install_src http://archive.apache.org/dist/spark/spark-2.0.0/spark-2.0.0-bin-hadoop2.7.tgz</div></pre></td></tr></table></figure>
</li>
<li><p>解壓縮下載檔案</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">tar -zxvf /bgdt/install_src/spark-2.0.0-bin-hadoop2.7.tgz -C /bgdt</div><div class="line">mv /bgdt/spark-2.0.0-bin-hadoop2.7 /bgdt/spark-2.0.0	##目錄名稱太長了,所以把目錄名稱改短</div></pre></td></tr></table></figure>
</li>
<li><p>修改~/.bashrc</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">export SPARK_HOME=/bgdt/spark-2.0.0</div><div class="line"></div><div class="line">將檔案儲存後,記得下source,讓設定生效</div><div class="line">[hadoop@mna1 ~]$source ~/.bashrc</div></pre></td></tr></table></figure>
</li>
<li><p>測試</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">##進入spark-shell</div><div class="line">[hadoop@mna1 ~]$/bgdt/spark-2.0.0/bin/sparl-shell</div><div class="line">......</div><div class="line">......</div><div class="line">scala&gt;</div></pre></td></tr></table></figure>
</li>
<li><p>spark-shell畫面截圖<br><img src="/images/spark_2.jpg" alt=""></p>
</li>
<li><p>Spark Scala Shell Test</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">[CTRL+l] &lt;--清除shell畫面</div><div class="line">scala&gt;sc</div><div class="line">scala&gt;spark</div></pre></td></tr></table></figure>
</li>
<li><p>Spark Example for Scala-建立檔案內容並上傳至HDFS</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">[hadoop@mna1 ~]$hadoop fs -mkdir -p /user/hadoop/ccc</div><div class="line">[hadoop@mna1 ~]$echo &quot;1,\&quot;test1\&quot;,10000&quot; &gt;&gt; test1.csv</div><div class="line">[hadoop@mna1 ~]$echo &quot;2,\&quot;test2\&quot;,20000&quot; &gt;&gt; test1.csv</div><div class="line">[hadoop@mna1 ~]$echo &quot;3,\&quot;test3\&quot;,30000&quot; &gt;&gt; test1.csv</div><div class="line">[hadoop@mna1 ~]$echo &quot;4,\&quot;test4\&quot;,40000&quot; &gt;&gt; test1.csv</div><div class="line">[hadoop@mna1 ~]$echo &quot;5,\&quot;test5\&quot;,50000&quot; &gt;&gt; test1.csv</div><div class="line">[hadoop@mna1 ~]$cat test1.csv</div><div class="line">[hadoop@mna1 ~]$hadoop fs -put ~/test1.csv /user/hadoop/ccc</div></pre></td></tr></table></figure>
</li>
<li><p>Spark Example for Scala-spark for scala程式撰寫</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">scala&gt;val distFile = sc.textFile(&quot;/user/hadoop/ccc/test1.csv&quot;)</div><div class="line">scala&gt;distFile.count()</div><div class="line">scala&gt;distFile.collect()</div></pre></td></tr></table></figure>
</li>
<li><p>範例執行結果<br><img src="/images/spark_shell_3.jpg" alt=""></p>
</li>
</ol>
<h3 id="MariaDB安裝-10-1-17"><a href="#MariaDB安裝-10-1-17" class="headerlink" title="MariaDB安裝(10.1.17)"></a>MariaDB安裝(10.1.17)</h3><ol>
<li>下載MariaDB安裝檔(目前最新版本為10.1.20)<br><a href="http://ftp.ubuntu-tw.org/mirror/mariadb//mariadb-10.1.17/bintar-linux-x86_64/mariadb-10.1.17-linux-x86_64.tar.gz" target="_blank" rel="external">Download mariadb-10.1.17-linux-x86_64</a><br><img src="/images/mariadb_install_1.jpg" alt=""></li>
<li><p>關閉iptables service</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line">先以root權限登入系統並關閉iptables服務</div><div class="line">[root@mna1 ~]$service iptables stop</div><div class="line">[root@mna1 ~]$service iptables status</div><div class="line"></div><div class="line">建立mysql帳號:</div><div class="line">[root@mna1 ~]$groupadd mysql</div><div class="line">[root@mna1 ~]$useradd -g mysql mysql</div><div class="line"></div><div class="line">安裝MariaDB</div><div class="line">[root@mna1 ~]cd /usr/local</div><div class="line">[root@mna1 local]$tar -zxvf /bgdt/install_src/mariadb-10.1.17-linux-x86_64.tar.gz -C /usr/local</div><div class="line">[root@mna1 local]$ln -s mariadb-10.1.17-linux-x86_64 mysql</div><div class="line">[root@mna1 local]$cd mysql</div><div class="line">[root@mna1 mysql]$./scripts/mysql_install_db --user=mysql</div><div class="line">[root@mna1 mysql]$chown -R root .</div><div class="line">[root@mna1 mysql]$chown -R mysql data</div><div class="line"></div><div class="line">啟動MariaDB</div><div class="line">[root@mna1 mysql]$nohup ./bin/mysqld &amp;</div><div class="line">[root@mna1 mysql]$./bin/mysqladmin -u root password &apos;!QAZxsw2&apos;  --socket=/var/lib/mysql/mysql.sock </div><div class="line">[root@mna1 mysql]$./bin/mysql -p  --socket=/var/lib/mysql/mysql.sock</div><div class="line">輸入密碼:!QAZxsw2</div><div class="line"></div><div class="line">設定權限</div><div class="line">mariadb&gt;create database metastore_db;</div><div class="line">mariadb&gt;SELECT User, Host FROM mysql.user WHERE Host &lt;&gt; &apos;localhost&apos;; </div><div class="line">mariadb&gt;GRANT ALL PRIVILEGES ON *.* TO &apos;root&apos;@&apos;%&apos; IDENTIFIED BY &apos;!QAZxsw2&apos; WITH GRANT OPTION;</div><div class="line">mariadb&gt;FLUSH PRIVILEGES;</div></pre></td></tr></table></figure>
</li>
<li><p>觀察3306 Port是否有開啟</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[root@mna1 ~]$netstat -tnl | grep &quot;3306&quot;</div></pre></td></tr></table></figure>
</li>
<li><p>確認”3306” Port是否有開啟？並且關閉確認關閉iptables<br><img src="/images/mariadb_install_2.jpg" alt=""></p>
</li>
</ol>
<h3 id="Hive安裝-2-1-1"><a href="#Hive安裝-2-1-1" class="headerlink" title="Hive安裝(2.1.1)"></a>Hive安裝(2.1.1)</h3><ol>
<li>下載 Hive安裝檔/原始碼<br><a href="http://apache.stu.edu.tw/hive/hive-2.1.1/apache-hive-2.1.1-bin.tar.gz" target="_blank" rel="external">Download Hive 安裝檔,apache-hive-2.1.1-bin</a><br><a href="http://apache.stu.edu.tw/hive/hive-2.1.1/apache-hive-2.1.1-src.tar.gz" target="_blank" rel="external">Download Hive 原始碼,apache-hive-2.1.1-src</a><br><img src="/images/hive_install_1.jpg" alt=""></li>
<li><p>解壓縮檔案</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">tar -zxvf /bgdt/install_src/apache-hive-2.1.1-bin.tar.gz -C /bgdt</div><div class="line">mv /bgdt/apache-hive-2.1.1-bin /bgdt/hive-2.1.1</div></pre></td></tr></table></figure>
</li>
<li><p>修改~/.bashrc</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">export HIVE_HOME=/bgdt/hive-2.1.1</div><div class="line">export PATH= $HIVE_HOME\bin:$PATH</div><div class="line">儲存檔案</div><div class="line"></div><div class="line">source ~/.bashrc</div></pre></td></tr></table></figure>
</li>
<li><p>將mysql-connector-java-5.1.39-bin.jar copy to /bgdt/hive-2.1.1/lib目錄下</p>
</li>
<li><p>建立Hive Warehouse</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">hadoop fs -mkdir -p /user/hive/warehouse</div><div class="line">hadoop fs -mkdir -p /tmp/hive</div></pre></td></tr></table></figure>
</li>
<li><p>Modify hive-site.xml</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div></pre></td><td class="code"><pre><div class="line">&lt;property&gt;</div><div class="line">    &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;</div><div class="line">    &lt;value&gt;jdbc:mysql://192.168.XXX.XXX:3306/metastore_db&lt;/value&gt;</div><div class="line">    &lt;description&gt;JDBC connect string for a JDBC metastore &lt;/description&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">    &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;</div><div class="line">    &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;</div><div class="line">    &lt;description&gt;Driver class name for a JDBC metastore&lt;/description&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">    &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;</div><div class="line">    &lt;value&gt;root&lt;/value&gt;</div><div class="line">    &lt;description&gt;username to use against metastore database&lt;/description&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">    &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;</div><div class="line">    &lt;value&gt;XXXXXXXXX&lt;/value&gt;</div><div class="line">    &lt;description&gt;password to use against metastore database&lt;/description&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">    &lt;name&gt;hive.exec.scratchdir&lt;/name&gt;</div><div class="line">    &lt;value&gt;/tmp/hive&lt;/value&gt;</div><div class="line">    &lt;description&gt;HDFS root scratch dir for Hive jobs which gets created with write all (733) permission. For each connecting user, an HDFS scratch dir: $&#123;hive.exec.scratchdir&#125;/&amp;lt;username&amp;gt; is created, with $&#123;hive.scratch.dir.permission&#125;.&lt;/description&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">    &lt;name&gt;hive.exec.local.scratchdir&lt;/name&gt;</div><div class="line">    &lt;value&gt;/tmp&lt;/value&gt;</div><div class="line">    &lt;description&gt;Local scratch space for Hive jobs&lt;/description&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">    &lt;name&gt;hive.downloaded.resources.dir&lt;/name&gt;</div><div class="line">    &lt;value&gt;/tmp&lt;/value&gt;</div><div class="line">    &lt;description&gt;Temporary local directory for added resources in the remote file system.&lt;/description&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">    &lt;name&gt;hive.scratch.dir.permission&lt;/name&gt;</div><div class="line">    &lt;value&gt;775&lt;/value&gt;</div><div class="line">    &lt;description&gt;The permission for the user specific scratch directories that get created.&lt;/description&gt;</div><div class="line">&lt;/property&gt;</div></pre></td></tr></table></figure>
</li>
<li><p>第一次建立時</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">##此動作會在mariadb的metastore_db中建立Hive用到的系統表格(以下動作會將meta資料重建)</div><div class="line">[hadoop@mna1 ~]$schematool -dbType mysql -initSchema</div></pre></td></tr></table></figure>
</li>
<li><p>在命令列中執行HiveCLI</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">[hadoop@mna1 ~]$hive</div><div class="line">......</div><div class="line">......</div><div class="line">hive&gt;</div></pre></td></tr></table></figure>
</li>
<li><p>在hive的CLI下建立Database及Table</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">hive&gt;create database test1;</div><div class="line">hive&gt;create table test1.staff(id int, name string, salary double) row format delimited fields terminated by &apos;,&apos;;</div><div class="line">hive&gt;LOAD DATA INPATH &apos;/user/hadoop/ccc/test1.csv&apos; overwrite into table test1.staff;</div><div class="line">hive&gt;select * from test1.staff;</div></pre></td></tr></table></figure>
</li>
<li><p>以上命令執行結果:<br><img src="/images/hive_shell_1.jpg" alt=""></p>
</li>
<li><p>HWI安裝<br>將已下載的Hive Souce code解壓縮至/bgdt</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">[hadoop@mna1 ~]$tar -zxvf /bgdt/install_src/apache-hive-2.1.1-src.tar.gz -C /bgdt</div><div class="line">[hadoop@mna1 ~]$cd /bgdt/apache-hive-2.1.1-src/hwi</div><div class="line">[hadoop@mna1 hwi]$ jar cfM hive-hwi-2.1.1.war -C web .</div><div class="line">[hadoop@mna1 hwi]$cp hive-hwi-2.1.1.war /bgdt/hive-2.1.1/lib/*</div></pre></td></tr></table></figure>
</li>
<li><p>修改hive-site.xml</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">&lt;property&gt;</div><div class="line">    &lt;name&gt;hive.hwi.listen.host&lt;/name&gt;</div><div class="line">    &lt;value&gt;mna1&lt;/value&gt;</div><div class="line">    &lt;description&gt;This is the host address the Hive Web Interface will listen on&lt;/description&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">    &lt;name&gt;hive.hwi.listen.port&lt;/name&gt;</div><div class="line">    &lt;value&gt;9999&lt;/value&gt;</div><div class="line">    &lt;description&gt;This is the port the Hive Web Interface will listen on&lt;/description&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">    &lt;name&gt;hive.hwi.war.file&lt;/name&gt;</div><div class="line">    &lt;value&gt;lib/hive-hwi-2.1.1.war&lt;/value&gt;</div><div class="line">    &lt;description&gt;This sets the path to the HWI war file, relative to $&#123;HIVE_HOME&#125;. &lt;/description&gt;</div><div class="line">&lt;/property&gt;</div></pre></td></tr></table></figure>
</li>
<li><p>Start HWI Service</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">##HWI啟動Port(9999)</div><div class="line">[hadoop@hadoop-master ~]$ nohup hive --service hwi &amp;</div><div class="line">[hadoop@hadoop-master ~]$ netstat -tnl | grep &quot;9999&quot;</div></pre></td></tr></table></figure>
</li>
<li><p>HWI介面(請連到<a href="http://XXX.XXX.XXX.XXX:9999/hwi" target="_blank" rel="external">http://XXX.XXX.XXX.XXX:9999/hwi</a>)<br><img src="/images/hive_hwi_1.jpg" alt=""></p>
</li>
<li><p>Start hiveserver2</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">##啟動Hive JDBC Port(port:10000)</div><div class="line">[hadoop@mna1 ~]$ nohup hive --service hiveserver2 &amp;</div><div class="line">[hadoop@mna1 ~]$ netstat -tnl | grep &quot;10000&quot;</div></pre></td></tr></table></figure>
</li>
<li><p>使用beeline連線Hive(須連線HiveServer2)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">[hadoop@mna1 ~]$ beeline</div><div class="line">beeline&gt; !connect jdbc:hive2://192.168.11.96:10000/default</div></pre></td></tr></table></figure>
</li>
</ol>
<h3 id="OOZIE安裝-4-3-0"><a href="#OOZIE安裝-4-3-0" class="headerlink" title="OOZIE安裝(4.3.0)"></a>OOZIE安裝(4.3.0)</h3><ol>
<li>從Github下載oozie原始碼,編譯oozie,並產生”oozie-4.3.0-SNAPSHOT.tar.gz”檔案</li>
<li><p>解壓縮oozie-4.3.0-SNAPSHOT.tar.gz並變更目錄名稱</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">sudo tar -zxvf /bgdt/install_src/oozie-4.3.0-SNAPSHOT.tar.gz -C /bgdt</div><div class="line">sudo chown -R hadoop:hadoop /bgdt/oozie-4.3.0-SNAPSHOT</div><div class="line">sudo mv /bgdt/oozie-4.3.0-SNAPSHOT /bgdt/oozie-4.3.0</div></pre></td></tr></table></figure>
</li>
<li><p>搬移相關lib至libext目錄</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">mkdir -p /bgdt/oozie-4.3.0/libext</div><div class="line">cp /bgdt/hadoop-2.7.2/share/hadoop/*/*.jar /bgdt/oozie-4.3.0/libext/</div><div class="line">cp /bgdt/hadoop-2.7.2/share/hadoop/*/lib/*.jar /bgdt/oozie-4.3.0/libext/</div><div class="line">rm -rf /bgdt/oozie-4.3.0/libext/jsp-api-2.1.jar</div><div class="line">cp /bgdt/install_src/ext2-2.zip /bgdt/oozie-4.3.0/libext</div></pre></td></tr></table></figure>
</li>
<li><p>安裝相關Server,createdb</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">cd /bgdt/oozie-4.3.0</div><div class="line">./bin/oozie-setup.sh prepare-war</div><div class="line">./bin/oozie-setup.sh db create -run</div><div class="line">./bin/oozied.sh start</div><div class="line">./bin/oozie admin -oozie http://localhost:11000/oozie -status</div></pre></td></tr></table></figure>
</li>
<li><p>OOZIE WEB UI:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">http://hadoop-master:11000/oozie</div></pre></td></tr></table></figure>
</li>
<li><p>安裝sharelib</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">cd /bgdt/oozie-4.3.0</div><div class="line">tar -zxvf oozie-sharelib-4.3.0-SNAPSHOT.tar.gz</div><div class="line">rm -rf /bgdt/oozie-4.3.0/share/lib/spark</div><div class="line">mkdir -p /bgdt/oozie-4.3.0/share/lib/spark</div><div class="line">cp /bgdt/spark/jars/* /bgdt/oozie-4.3.0/share/lib/spark</div><div class="line">cp oozie-sharelib-oozie-4.3.0-SNAPSHOT.jar  /bgdt/oozie-4.3.0/share/lib/spark</div><div class="line">cp oozie-sharelib-spark-4.3.0-SNAPSHOT.jar  /bgdt/oozie-4.3.0/share/lib/spark</div><div class="line">cp /bgdt/hive-2.1.1/conf/hive-site.xml  /bgdt/oozie-4.3.0/share/lib/spark</div><div class="line">cp /bgdt/install_src/mysql-connector-java-5.1.39-bin.jar /bgdt/oozie-4.3.0/share/lib/spark</div></pre></td></tr></table></figure>
</li>
<li><p>在HDFS上建立sharelib相關目錄</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">hadoop fs -mkdir -p /user/hadoop/share/lib</div><div class="line">hadoop fs -put /bgdt/oozie-4.3.0/share/lib/* /user/hadoop/share/lib</div></pre></td></tr></table></figure>
</li>
<li><p>重啟oozie</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">cd /bgdt/oozie-4.3.0</div><div class="line">./bin/oozied.sh stop</div><div class="line">./bin/oozied.sh start</div></pre></td></tr></table></figure>
</li>
<li><p>執行oozie提供相關的測試範例:<br>9.1 上傳oozie examples相關設定到 hdfs</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">tar -zxvf oozie-examples.tar.gz</div><div class="line">hadoop fs -mkdir -p /user/hadoop/oozie/examples</div><div class="line">hadoop fs -put -f /bgdt/oozie-4.3.0/examples/* /user/hadoop/oozie/examples</div></pre></td></tr></table></figure>
<p>9.2 修改job.properties </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">cd /bgdt/oozie-4.3.0/examples/apps/spark</div><div class="line">vi ./job.properties</div><div class="line"></div><div class="line">##修改以下內容</div><div class="line">nameNode=hdfs://hadoop-master:8020</div><div class="line">jobTracker=hadoop-master:8032</div><div class="line">master=local[*]</div><div class="line">queueName=default</div><div class="line">examplesRoot=examples</div><div class="line">oozie.use.system.libpath=true</div><div class="line">oozie.wf.application.path=/user/hadoop/oozie/examples/apps/spark</div></pre></td></tr></table></figure>
<p>9.3 執行oozie example </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">cd /bgdt/oozie-4.3.0</div><div class="line">./bin/oozie job -oozie http://localhost:11000/oozie -config ./examples/apps/spark/job.properties -run</div><div class="line">./bin/oozie job -oozie http://localhost:11000/oozie -config ./examples/apps/map-reduce/job.properties -run</div></pre></td></tr></table></figure>
<p>9.4 到WebUI觀察執行情形 </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">http://hadoop-master:8088</div></pre></td></tr></table></figure>
</li>
</ol>
<h3 id="Anaconda3安裝-4-2-0-選裝"><a href="#Anaconda3安裝-4-2-0-選裝" class="headerlink" title="Anaconda3安裝(4.2.0),選裝"></a>Anaconda3安裝(4.2.0),選裝</h3><ol>
<li><p>Download Anaconda3-4.2.0-Linux-x86.sh<br><a href="https://repo.continuum.io/archive/" target="_blank" rel="external">https://repo.continuum.io/archive/</a><br><a href="https://www.continuum.io/downloads" target="_blank" rel="external">https://www.continuum.io/downloads</a></p>
</li>
<li><p>Upload Anaconda3-4.2.0-Linux-x86.sh to Host</p>
</li>
<li><p>Install bzip2(if not bzip2)       </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo yum install bzip2 -y</div></pre></td></tr></table></figure>
</li>
<li><p>Install Anaconda3    </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">bash /opt/Anaconda3-4.2.0-Linux-x86.sh</div><div class="line">&gt;&gt;&gt;[Enter]</div><div class="line">......</div><div class="line">&gt;&gt;&gt;yes</div><div class="line">......</div><div class="line">&gt;&gt;&gt;/opt/anaconda3</div><div class="line">......</div><div class="line">&gt;&gt;&gt;yes</div><div class="line">......</div></pre></td></tr></table></figure>
</li>
<li><p>Modify ~/.bashrc  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"># added by Anaconda3 4.2.0 installer</div><div class="line">export PATH=&quot;/opt/anaconda3/bin:$PATH&quot;</div></pre></td></tr></table></figure>
</li>
<li><p>Modify spark-env.sh  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">vi /usr/local/spark/conf/spark/spark-env.sh</div></pre></td></tr></table></figure>
</li>
<li><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">export PYSPARK_PYTHON=/opt/anaconda3/bin/python3</div><div class="line">export PYSPARK_DRIVER_PYTHON=jupyter</div><div class="line">export PYSPARK_DRIVER_PYTHON_OPTS=&quot;notebook --NotebookApp.open_browser=False --NotebookApp.ip=&apos;*&apos; --NotebookApp.port=8880&quot;</div></pre></td></tr></table></figure>
</li>
<li><p>重新進入Putty後,啟動Hadoop相關服務  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">start-dfs.sh  ##start Hadoop</div><div class="line">start-yarn.sh ##start yarn</div><div class="line">nohup /usr/local/spark/bin/pyspark &amp;</div></pre></td></tr></table></figure>
</li>
<li><p>啟動完成後,打開Web Browser即可看到Jupyter Web UI<br><img src="/images/jupyter_1.jpg" alt=""></p>
</li>
<li><p>以下編寫測試範例:<br><img src="/images/jupyter_2.jpg" alt=""></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">rdd = sc.textFile(&quot;hdfs://XXX.XXX.XXX.XXX:8020/OOO/readme.txt&quot;)</div><div class="line">rdd.count()</div></pre></td></tr></table></figure>
</li>
<li><p>操作DataFrame範例:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">l = [(&apos;Alice&apos;, 1)]</div><div class="line">spark.createDataFrame(l).collect()</div><div class="line">spark.createDataFrame(l, [&apos;name&apos;, &apos;age&apos;]).collect()</div></pre></td></tr></table></figure>
</li>
<li><p>使用Spark SQL取得資料</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">ds = spark.sql(&quot;select * from students&quot;)</div><div class="line">ds.take(5)</div></pre></td></tr></table></figure>
</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/01/08/BigData/" data-id="cixoq9nnc0000eslls1eeyijx" class="article-share-link">Partager</a>
      
        <a href="http://yoursite.com/2017/01/08/BigData/#disqus_thread" class="article-comment-link">Commentaires</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/環境安裝/">環境安裝</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Linux" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/12/07/Linux/" class="article-date">
  <time datetime="2016-12-07T14:05:00.000Z" itemprop="datePublished">2016-12-07</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/technology/">技術之路</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/12/07/Linux/">常用Linux 命令筆記(for Oracle Linux)</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
<div id="toc">
  <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#常用指令"><span class="toc-text">常用指令</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#新增使用者及密碼修改"><span class="toc-text">新增使用者及密碼修改</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#系統關機或重啟命令-非”Root”使用者-須加入sudo"><span class="toc-text">系統關機或重啟命令(非”Root”使用者,須加入sudo)</span></a></li></ol></li></ol>
</div>

        <h2 id="常用指令"><a href="#常用指令" class="headerlink" title="常用指令"></a>常用指令</h2><h3 id="新增使用者及密碼修改"><a href="#新增使用者及密碼修改" class="headerlink" title="新增使用者及密碼修改"></a>新增使用者及密碼修改</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">[root@hadoop-master]$useradd hadoop</div><div class="line">[root@hadoop-master]$passwd hadoop</div><div class="line">[root@hadoop-master]$visudo #如果須要讓 &quot;hadoop&quot;使用者暫時具有管理者(root)權限的話,須使用此指令編輯檔案</div><div class="line">......</div><div class="line">root    ALL=(ALL) ALL ##在此行後面加入</div><div class="line">......</div><div class="line">hadoop  ALL=(ALL) ALL</div><div class="line">......</div></pre></td></tr></table></figure>
<h3 id="系統關機或重啟命令-非”Root”使用者-須加入sudo"><a href="#系統關機或重啟命令-非”Root”使用者-須加入sudo" class="headerlink" title="系統關機或重啟命令(非”Root”使用者,須加入sudo)"></a>系統關機或重啟命令(非”Root”使用者,須加入sudo)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">[hadoop@hadoop-master ~]$sudo shutdown -h now        ##系統立刻關機 </div><div class="line">[hadoop@hadoop-master ~]$sudo shutdown -r now        ##系統立刻重新開機 </div><div class="line">[hadoop@hadoop-master ~]$sudo shutdown -h 20:30      ##系統在今天的 20:30 分關機 </div><div class="line">[hadoop@hadoop-master ~]$sudo shutdown -h +10        ##系統在 10 分鐘後關機</div><div class="line">[hadoop@hadoop-master ~]$sudo sync;sync;sync;reboot  ##重新開機指令,配合寫入緩衝資料的sync指令動作</div><div class="line">[hadoop@hadoop-master ~]$sudo init 0                 ##關機</div><div class="line">[hadoop@hadoop-master ~]$sudo init 6                 ##重新啟動</div></pre></td></tr></table></figure>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/12/07/Linux/" data-id="cixoq9nnh0001eslla19zh2or" class="article-share-link">Partager</a>
      
        <a href="http://yoursite.com/2016/12/07/Linux/#disqus_thread" class="article-comment-link">Commentaires</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/命令/">命令</a></li></ul>

    </footer>
  </div>
  
</article>


  

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Catégories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/technology/">技術之路</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Mot-clés</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/命令/">命令</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/環境安裝/">環境安裝</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Nuage de mot-clés</h3>
    <div class="widget tagcloud">
      <a href="/tags/命令/" style="font-size: 10px;">命令</a> <a href="/tags/環境安裝/" style="font-size: 10px;">環境安裝</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/01/">January 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/12/">December 2016</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Articles récents</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2017/01/08/BigData/">Hadoop Cluster相關環境建置筆記(持續更新中)</a>
          </li>
        
          <li>
            <a href="/2016/12/07/Linux/">常用Linux 命令筆記(for Oracle Linux)</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2017 popal<br>
      Propulsé by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    
<script>
  var disqus_shortname = 'popal';
  
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/count.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>


<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>