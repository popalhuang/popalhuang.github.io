<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Popal&#39;s Blog</title>
  <subtitle>邊做邊學</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2017-05-22T11:01:54.357Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>popal</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Spark程式開發系列_for Java1.8_001</title>
    <link href="http://yoursite.com/2017/05/22/%5Bspark%5Dspark_001/"/>
    <id>http://yoursite.com/2017/05/22/[spark]spark_001/</id>
    <published>2017-05-21T16:00:00.000Z</published>
    <updated>2017-05-22T11:01:54.357Z</updated>
    
    <content type="html"><![CDATA[<h3 id="SparkSession-Example-1"><a href="#SparkSession-Example-1" class="headerlink" title="SparkSession Example 1"></a>SparkSession Example 1</h3><ol>
<li><p>使用vi,或先用記事本建立以下json檔案(我的是建立在/home/vagrant/src/job/person5_data.json)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&#123;&quot;id&quot;:&quot;0000000001&quot;,&quot;name&quot;:&quot;Test001&quot;,&quot;gender&quot;:&quot;M&quot;,&quot;age&quot;:&quot;40&quot;,&quot;telphone&quot;:&quot;123456789&quot;,&quot;address&quot;:&#123;&quot;country&quot;:&quot;Taiwan&quot;,&quot;city&quot;:&quot;Taipei&quot;,&quot;state&quot;:&quot;Sanxia&quot;,&quot;street&quot;:&quot;test.&quot;&#125;,&quot;child&quot;:[&#123;&quot;age&quot;:&quot;5&quot;,&quot;name&quot;:&quot;sub_001&quot;,&quot;gender&quot;:&quot;M&quot;&#125;,&#123;&quot;age&quot;:&quot;6&quot;,&quot;name&quot;:&quot;sub_002&quot;,&quot;gender&quot;:&quot;M&quot;&#125;]&#125;,</div><div class="line">&#123;&quot;id&quot;:&quot;0000000002&quot;,&quot;name&quot;:&quot;Test002&quot;,&quot;gender&quot;:&quot;F&quot;,&quot;age&quot;:&quot;29&quot;,&quot;telphone&quot;:&quot;223456670&quot;,&quot;address&quot;:&#123;&quot;country&quot;:&quot;Taiwan&quot;,&quot;city&quot;:&quot;Taipei&quot;,&quot;state&quot;:&quot;Sanzhi&quot;,&quot;street&quot;:&quot;test.&quot;&#125;,&quot;child&quot;:[&#123;&quot;age&quot;:&quot;7&quot;,&quot;name&quot;:&quot;sub_003&quot;,&quot;gender&quot;:&quot;M&quot;&#125;,&#123;&quot;age&quot;:&quot;8&quot;,&quot;name&quot;:&quot;sub_004&quot;,&quot;gender&quot;:&quot;F&quot;&#125;]&#125;</div></pre></td></tr></table></figure>
</li>
<li><p>將person5_data.json檔案放到HDFS目錄上</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hadoop fs -put -f /home/vagrant/src/job/person5_data.json /user/hadoop/data</div></pre></td></tr></table></figure>
</li>
<li><p>Create SparkSession</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line">import org.apache.spark.sql.AnalysisException;</div><div class="line">import org.apache.spark.sql.Dataset;</div><div class="line">import org.apache.spark.sql.Row;</div><div class="line">import org.apache.spark.sql.SaveMode;</div><div class="line">import org.apache.spark.sql.SparkSession;</div><div class="line">import org.apache.spark.sql.catalog.Database;</div><div class="line"></div><div class="line">public class SparkExample0 &#123;</div><div class="line"></div><div class="line">	public static void main(String[] args) throws AnalysisException &#123;</div><div class="line">		</div><div class="line">		//1. Create SparkSession</div><div class="line">		SparkSession spark = SparkSession.builder()	</div><div class="line">			.master(&quot;local&quot;)												</div><div class="line">			.config(&quot;spark.executor.memory&quot;, &quot;2g&quot;)	</div><div class="line">			.appName(&quot;SparkExample0&quot;)								</div><div class="line">			.enableHiveSupport()										</div><div class="line">			.getOrCreate();													</div><div class="line">		</div><div class="line">		//2. set new runtime options</div><div class="line">		spark.conf().set(&quot;spark.sql.shuffle.partitions&quot;, 6);</div><div class="line">						</div><div class="line">		//3. SparkSession-透過read方式來讀取各種不同來源的資料						</div><div class="line">		Dataset&lt;Row&gt; ds1 = spark.read().format(&quot;json&quot;).load(&quot;/user/hadoop/data/person5_data.json&quot;);</div><div class="line">		ds1.printSchema();</div><div class="line">		</div><div class="line">		//4. 將檔案存成Hive資料表</div><div class="line">		ds1.repartition(1).write().mode(SaveMode.Overwrite).saveAsTable(&quot;example.person_data5&quot;);													</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
<li><p>使用spark-submit執行Java Spark程式</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">spark-submit --class &quot;SparkExample0&quot; /home/vagrant/src/job/Spark2Example.jar</div></pre></td></tr></table></figure>
</li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;SparkSession-Example-1&quot;&gt;&lt;a href=&quot;#SparkSession-Example-1&quot; class=&quot;headerlink&quot; title=&quot;SparkSession Example 1&quot;&gt;&lt;/a&gt;SparkSession Example
    
    </summary>
    
      <category term="Spark" scheme="http://yoursite.com/categories/Spark/"/>
    
    
  </entry>
  
  <entry>
    <title>Vagrant Command Line說明筆記</title>
    <link href="http://yoursite.com/2017/02/20/%5Bvagrant%5DVagrantMemo/"/>
    <id>http://yoursite.com/2017/02/20/[vagrant]VagrantMemo/</id>
    <published>2017-02-19T16:00:00.000Z</published>
    <updated>2017-02-20T05:35:44.382Z</updated>
    
    <content type="html"><![CDATA[<h4 id="vagrant-box"><a href="#vagrant-box" class="headerlink" title="vagrant box"></a>vagrant box</h4><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">vagrant box add ubuntu/precise64	##https://atlas.hashicorp.com/</div><div class="line">vagrant box add precise64 http://files.vagrantup.com/precise64.box</div><div class="line">vagrant box list</div><div class="line">vagrant box remove precise64</div></pre></td></tr></table></figure>
</blockquote>
<h4 id="vagrant-init"><a href="#vagrant-init" class="headerlink" title="vagrant init"></a>vagrant init</h4><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">vagrant init  precise64	##會在執行語法的目錄下產生一個Vagrantfile的配置檔</div></pre></td></tr></table></figure>
</blockquote>
<h4 id="vagrant-啟動-停止-重啟-移除-全部VM"><a href="#vagrant-啟動-停止-重啟-移除-全部VM" class="headerlink" title="vagrant 啟動/停止/重啟/移除 全部VM"></a>vagrant 啟動/停止/重啟/移除 全部VM</h4><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">##以下為啟動/停止/重啟/移除全部VM的用法</div><div class="line">vagrant up	##啟動全部VM</div><div class="line">vagrant halt	##停止全部VM</div><div class="line">vagrant reload	##重啟全部VM</div><div class="line">vagrant destroy	##移除全部VM</div><div class="line"></div><div class="line">##以下為啟動/停止/重啟/移除單一VM的用法</div><div class="line">vagrant up master</div><div class="line">vagrant halt master</div><div class="line">vagrant reload master</div><div class="line">vagrant destroy master</div><div class="line"></div><div class="line">##以下為啟動/停止/重啟/移除多個VM的用法(VM名稱中間空格,以做為多個VM名稱區隔)</div><div class="line">vagrant up master slave1</div><div class="line">vagrant halt master slave1</div><div class="line">vagrant reload master slave1</div><div class="line">vagrant destroy master slave1</div></pre></td></tr></table></figure></blockquote>
]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;vagrant-box&quot;&gt;&lt;a href=&quot;#vagrant-box&quot; class=&quot;headerlink&quot; title=&quot;vagrant box&quot;&gt;&lt;/a&gt;vagrant box&lt;/h4&gt;&lt;blockquote&gt;
&lt;figure class=&quot;highlight
    
    </summary>
    
      <category term="vagrant" scheme="http://yoursite.com/categories/vagrant/"/>
    
    
  </entry>
  
  <entry>
    <title>Vagrant file 配置檔案說明</title>
    <link href="http://yoursite.com/2017/02/20/%5Bvagrant%5DVagrantfile%E9%85%8D%E7%BD%AE%E6%AA%94%E8%AA%AA%E6%98%8E/"/>
    <id>http://yoursite.com/2017/02/20/[vagrant]Vagrantfile配置檔說明/</id>
    <published>2017-02-19T16:00:00.000Z</published>
    <updated>2017-02-20T06:02:47.965Z</updated>
    
    <content type="html"><![CDATA[<h4 id="vagrant-file配置檔案說明"><a href="#vagrant-file配置檔案說明" class="headerlink" title="vagrant file配置檔案說明"></a>vagrant file配置檔案說明</h4><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div></pre></td><td class="code"><pre><div class="line"># -*- mode: ruby -*-</div><div class="line"># vi: set ft=ruby :</div><div class="line"></div><div class="line">MASTER_IP	= &apos;192.168.51.4&apos;</div><div class="line">DN1_IP		= &apos;192.168.51.5&apos;</div><div class="line">DN2_IP		= &apos;192.168.51.6&apos;</div><div class="line"></div><div class="line">Vagrant.configure(&quot;2&quot;) do |config|  </div><div class="line">  config.ssh.insert_key =false  </div><div class="line">   </div><div class="line">  #define data1 server</div><div class="line">  config.vm.define &quot;slave1&quot; do |slave1|</div><div class="line">	slave1.vm.hostname = &quot;hadoop-slave1&quot;		##設定VM主機名稱</div><div class="line">	slave1.vm.network &quot;private_network&quot;, ip: DN1_IP	##設定主機 ip</div><div class="line">	slave1.vm.box = &quot;ubuntu/yakkety64&quot;		##設定VM使用的OS Box</div><div class="line">	slave1.vm.synced_folder &quot;.&quot;, &quot;/home/vagrant/src&quot;, mount_options: [&quot;dmode=775,fmode=664&quot;]	##設定公用分享目錄	</div><div class="line">	slave1.vm.provider &quot;virtualbox&quot; do |v|</div><div class="line">		v.name = &quot;slave1&quot;</div><div class="line">		v.cpus = 1</div><div class="line">		v.memory = 2500</div><div class="line">	end    </div><div class="line">	slave1.vm.provision &quot;shell&quot;, path: &quot;bootstrap-slave.sh&quot;	##設定VM第一次被啟動時,所需執行的Shell,且使用root帳號執行</div><div class="line">  end</div><div class="line"></div><div class="line">  #define data2 server</div><div class="line">  config.vm.define &quot;slave2&quot; do |slave2|</div><div class="line">	slave2.vm.hostname = &quot;hadoop-slave2&quot;		##設定VM主機名稱</div><div class="line">	slave2.vm.network &quot;private_network&quot;, ip: DN2_IP	##設定主機 ip</div><div class="line">	slave2.vm.box = &quot;ubuntu/yakkety64&quot;		##設定VM使用的OS Box</div><div class="line">	slave2.vm.synced_folder &quot;.&quot;, &quot;/home/vagrant/src&quot;, mount_options: [&quot;dmode=775,fmode=664&quot;]	##設定公用分享目錄</div><div class="line">	slave2.vm.provider &quot;virtualbox&quot; do |v|</div><div class="line">		v.name = &quot;slave2&quot;	##設定VM名稱</div><div class="line">		v.cpus = 1		##設定VM所使用的CPU core數量</div><div class="line">		v.memory = 2500		##設定VM記憶體大小</div><div class="line">	end</div><div class="line">  	slave2.vm.provision &quot;shell&quot;, path: &quot;bootstrap-slave.sh&quot;	##設定VM第一次被啟動時,所需執行的Shell,且使用root帳號執行</div><div class="line">  end</div><div class="line">  </div><div class="line">  #define Master server</div><div class="line">  config.vm.define &quot;master&quot; do |master|</div><div class="line">	master.vm.hostname = &quot;hadoop-master&quot;			##設定VM主機名稱</div><div class="line">	master.vm.network &quot;private_network&quot;, ip: MASTER_IP	##設定主機 ip</div><div class="line">	master.vm.box = &quot;ubuntu/yakkety64&quot;			##設定VM使用的OS Box</div><div class="line">	master.vm.synced_folder &quot;.&quot;, &quot;/home/vagrant/src&quot;, mount_options: [&quot;dmode=775,fmode=664&quot;]	##設定公用分享目錄	</div><div class="line">	master.vm.provider &quot;virtualbox&quot; do |v|</div><div class="line">		v.name = &quot;master&quot;	##設定VM名稱</div><div class="line">		v.cpus = 1		##設定VM所使用的CPU core數量</div><div class="line">		v.memory = 3500		##設定VM記憶體大小</div><div class="line">	end    </div><div class="line">	master.vm.provision &quot;shell&quot;, path: &quot;bootstrap-master.sh&quot;					##設定VM第一次被啟動時,所需執行的Shell,且使用root帳號執行</div><div class="line">	#master.vm.provision &quot;shell&quot;, path: &quot;bootstrap-complete.sh&quot;, run: &quot;always&quot;			##每次啟動VM時,都必須執行的Shell,且使用root帳號執行</div><div class="line">	#master.vm.provision &quot;shell&quot;, path: &quot;bootstrap-complete.sh&quot;, run: &quot;always&quot;,privileged: false	##設定VM第一次被啟動時,所需執行的Shell,且使非root帳號執行</div><div class="line">  end   </div><div class="line">  </div><div class="line">end</div></pre></td></tr></table></figure></blockquote>
]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;vagrant-file配置檔案說明&quot;&gt;&lt;a href=&quot;#vagrant-file配置檔案說明&quot; class=&quot;headerlink&quot; title=&quot;vagrant file配置檔案說明&quot;&gt;&lt;/a&gt;vagrant file配置檔案說明&lt;/h4&gt;&lt;blockquo
    
    </summary>
    
      <category term="vagrant" scheme="http://yoursite.com/categories/vagrant/"/>
    
    
  </entry>
  
  <entry>
    <title>Hadoop資料儲存於多個目錄中的模擬測試</title>
    <link href="http://yoursite.com/2017/01/10/%5Bhadoop%5DhadoopMultiDirectoryStore/"/>
    <id>http://yoursite.com/2017/01/10/[hadoop]hadoopMultiDirectoryStore/</id>
    <published>2017-01-09T16:00:00.000Z</published>
    <updated>2017-01-10T09:59:13.871Z</updated>
    
    <content type="html"><![CDATA[<h3 id="環境說明"><a href="#環境說明" class="headerlink" title="環境說明"></a>環境說明</h3><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">namenode *1(for Linux OS)</div><div class="line">datanode *4(for Linux OS)</div></pre></td></tr></table></figure>
</blockquote>
<h4 id="相關設定說明"><a href="#相關設定說明" class="headerlink" title="相關設定說明"></a>相關設定說明</h4><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">mkdir -p /bgdt/data/data2</div><div class="line"></div><div class="line">##修改hdfs-site.xml</div><div class="line">&lt;property&gt;</div><div class="line">	&lt;name&gt;dfs.data.dir&lt;/name&gt;</div><div class="line">	&lt;value&gt;/bgdt/hadoop-2.7.2/tmp/dfs/data,/bgdt/data/data2&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">	&lt;name&gt;dfs.datanode.failed.volumes.tolerated&lt;/name&gt;</div><div class="line">	&lt;value&gt;1&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div></pre></td></tr></table></figure>
</blockquote>
<h3 id="進入劇本之前"><a href="#進入劇本之前" class="headerlink" title="進入劇本之前"></a>進入劇本之前</h3><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">##重啟dfs與yarn</div><div class="line">start-dfs.sh</div><div class="line">start-yarn.sh</div><div class="line"></div><div class="line">##並下達以下指令:</div><div class="line">hadoop balancer</div></pre></td></tr></table></figure>
</blockquote>
<h3 id="劇本1"><a href="#劇本1" class="headerlink" title="劇本1"></a>劇本1</h3><blockquote>
<p>系統Run了一段時間後,發現空間不夠了,想增加一個空間給目前的Hadoop cluster環境,因此有了以下的劇本與想法<br>1.用新加一個目錄,來取代模擬新分割區<br>2.copy 一個檔案至HDFS系統後,透過介面查詢相關block id,找出相對實體檔案的儲存位置</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">hadoop fs -mkdir -P /user/hadoop/data</div><div class="line">hadoop fs -put /opt/staff.csv /user/hadoop/data</div><div class="line"></div><div class="line">##打開Web UI觀察 /user/hadoop/data/staff.csv block Id=XXXXXX</div><div class="line">在檔案下載畫面中會有檔案相關資訊</div><div class="line">block Id:  </div><div class="line">Avaailable</div><div class="line">dna1</div><div class="line">dna3</div><div class="line"></div><div class="line">##確認block Id,與存放的Datanode位置後,直接查找存放的實體位置</div><div class="line">ssh dna1 &quot;find /bgdt -name &quot;blk_&lt;ID&gt;&quot;&quot;</div><div class="line">/bgdt/data/data2/current/BP-1008347755-192.168.11.96-1474254342729/current/finalized/subdir0/subdir0/blk_XXXXXX</div></pre></td></tr></table></figure>
</blockquote>
<h3 id="劇本2"><a href="#劇本2" class="headerlink" title="劇本2"></a>劇本2</h3><blockquote>
<p>將某個Datanode的某個目錄權限及owner設定成(chown root:root chmod 000),模擬硬碟損壞的狀況　<br>1.測試當某個正在運行的hadoop cluster節點的儲存目錄被設為無讀寫權限時,系統是否會Crash<br>2.當目錄修復完成後資料是否有辦法從其他的node,reconvert回來<br>3.當該某個正在運行的節點,所有目錄都無法讀取時,系統是否會正常運行<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line">##將測試檔案存放到HDFS,並設定副本數為4</div><div class="line">hadoop fs -Ddfs.replication=4 -put /opt/staff_1.csv /user/hadoop/data</div><div class="line"></div><div class="line">##查詢block Id 及block儲存位置</div><div class="line">ssh dna1 &quot;find /bgdt -name &quot;blk_&lt;ID&gt;&quot;&quot;</div><div class="line"></div><div class="line">##模擬故障</div><div class="line">sudo chown -R root:root /bgdt/hadoop-2.7.2/tmp</div><div class="line">sudo chmod -R 000 /bgdt/hadoop-2.7.2/tmp</div><div class="line">hadoop balancer</div><div class="line"></div><div class="line">##Web UI上Datanode Volume Failures會出現有問題的目錄</div><div class="line"></div><div class="line">##balencer執行完成後,會將原本在/tmp目錄下的資料搬移到 /bgdt/data/data2</div><div class="line"></div><div class="line">##此時若再把另外一個目錄也模擬成無權限狀態</div><div class="line">sudo chown -R root:root /bgdt/data</div><div class="line">sudo chmod -R 000 /bgdt/data</div><div class="line"></div><div class="line">##該node的Status會變成Dead,並且DataNode的process會停止</div><div class="line"></div><div class="line">##此時資料的Repl雖然一樣是4,但實際上的資料份數是3</div><div class="line"></div><div class="line">##接著將/bgdt/data目錄設回原本權限,並將資料刪除</div><div class="line">sudo chown -R hadoop:hadoop /bgdt/data</div><div class="line">sudo chmod -R 755 /bgdt/data</div><div class="line">rm -rf /bgdt/data</div><div class="line"></div><div class="line">##並將/bgdt/data目錄的資料刪除後,重啟datanode</div><div class="line">hadoop-daemon.sh start datanode</div><div class="line"></div><div class="line">##重啟成功後,進行balancer</div><div class="line">hadoop balancer</div><div class="line"></div><div class="line">##看到所有檔案的副本數與與資料又恢復正常</div></pre></td></tr></table></figure></p>
</blockquote>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;環境說明&quot;&gt;&lt;a href=&quot;#環境說明&quot; class=&quot;headerlink&quot; title=&quot;環境說明&quot;&gt;&lt;/a&gt;環境說明&lt;/h3&gt;&lt;blockquote&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class
    
    </summary>
    
      <category term="hadoop" scheme="http://yoursite.com/categories/hadoop/"/>
    
    
  </entry>
  
  <entry>
    <title>Hadoop Cluster-動態新增一個節點</title>
    <link href="http://yoursite.com/2017/01/10/%5Bhadoop%5DCreatNewDataNode/"/>
    <id>http://yoursite.com/2017/01/10/[hadoop]CreatNewDataNode/</id>
    <published>2017-01-09T16:00:00.000Z</published>
    <updated>2017-01-10T10:08:35.570Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>hadoop cluster Run了一段時間後,想要增加運算速度,因此想動態新增一個DataNode<br>1.動態新增一個DataNode</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">##新主機請安裝以下</div><div class="line">1.  安裝Linux OS</div><div class="line">2.  在/etc/hosts加入所有Hadoop cluster節點的hostname</div><div class="line">3.  進入NameNode下執行</div><div class="line">    ssh-copy-id hadoop@hadoop-slave5</div><div class="line">    scp hadoop-bin-2.7.2.tar.gz hadoop@hadoop-slave5:/bgdt/install_src</div><div class="line">4.  進入新增的DataNode</div><div class="line">5.  tar -zxvf jdk-8u101-linux-x64.tar.gz -C /bgdt/java</div><div class="line">6.  tar -zxvf hadoop-bin-2.7.2.tar.gz -C /bgdt</div><div class="line">7.  Modify ~/.bashrc</div><div class="line">8.  scp 相關設定檔</div><div class="line">    scp /bgdt/hadoop-2.7.2/etc/hadoop/hdfs-site.xml hadoop@hadoop-slave5:/bgdt/hadoop-2.7.2/etc/hadoop/hdfs-site.xml</div><div class="line">    scp /bgdt/hadoop-2.7.2/etc/hadoop/core-site.xml hadoop@hadoop-slave5:/bgdt/hadoop-2.7.2/etc/hadoop/core-site.xml</div><div class="line">    scp /bgdt/hadoop-2.7.2/etc/hadoop/mapred-site.xml hadoop@hadoop-slave5:/bgdt/hadoop-2.7.2/etc/hadoop/mapred-site.xml</div><div class="line">    scp /bgdt/hadoop-2.7.2/etc/hadoop/yarn-site.xml hadoop@hadoop-slave5:/bgdt/hadoop-2.7.2/etc/hadoop/yarn-site.xml</div><div class="line">    scp /bgdt/hadoop-2.7.2/etc/hadoop/slaves hadoop@hadoop-slave5:/bgdt/hadoop-2.7.2/etc/hadoop/slaves</div><div class="line">9.  hadoop-daemon.sh start datanode</div><div class="line">10. 觀察Web UI是否出現slave5 DataNode</div></pre></td></tr></table></figure>
</blockquote>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;hadoop cluster Run了一段時間後,想要增加運算速度,因此想動態新增一個DataNode&lt;br&gt;1.動態新增一個DataNode&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td c
    
    </summary>
    
      <category term="hadoop" scheme="http://yoursite.com/categories/hadoop/"/>
    
    
  </entry>
  
  <entry>
    <title>Hadoop常用命令說明</title>
    <link href="http://yoursite.com/2017/01/10/%5Bhadoop%5DHadoop_CMD/"/>
    <id>http://yoursite.com/2017/01/10/[hadoop]Hadoop_CMD/</id>
    <published>2017-01-09T16:00:00.000Z</published>
    <updated>2017-01-10T10:14:07.994Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div></pre></td><td class="code"><pre><div class="line">hadoop fs -mkdir    /user/hadoop/data                      </div><div class="line">hadoop fs -mkdir -p /user/hadoop/data                      ##連Partants Directories建立</div><div class="line"></div><div class="line">hadoop fs -ls -h[-d] /user/hadoop</div><div class="line">hadoop fs -lsr       /user/hadoop</div><div class="line"></div><div class="line">hadoop fs -put      /opt/staff.csv /user/hadoop/data       ##上傳檔案至HDFS,不會overwrite</div><div class="line">hadoop fs -put -f   /opt/staff.csv /user/hadoop/data       ##上傳檔案至HDFS,overwrite當前檔案</div><div class="line"></div><div class="line">hadoop fs -df -h    /user/hadoop</div><div class="line">hadoop fs -du -h    /user/hadoop</div><div class="line">hadoop fs -dus      /user/hadoop</div><div class="line">hadoop fs -Ddfs.replication=4 -put /opt/staff.csv /user/hadoop/data</div><div class="line">hadoop fs -setrep 10 /user/hadoop/data/staff.csv</div><div class="line"></div><div class="line"></div><div class="line">hadoop fs -mkdir -p /user/hadoop/ccc</div><div class="line"></div><div class="line">hadoop fs -touchz /user/hadoop/ccc/test.xml	##建立一個空檔案</div><div class="line"></div><div class="line">hadoop fs -cat    /user/hadoop/ccc/test.xml</div><div class="line"></div><div class="line"></div><div class="line">hadoop fs -rm    /user/hadoop/ccc/test.xml	##刪除HDFS上的檔案</div><div class="line">hadoop fs -rmdir /user/hadoop/ccc		##刪除HDFS上的空目錄</div><div class="line">hadoop fs -rmr   /user/hadoop/ccc		##刪除指定目錄下所有的檔案及目錄</div><div class="line"></div><div class="line"></div><div class="line">hadoop fs -copyFromLocal /opt/staff.csv /user/hadoop/ccc			##檔案上傳到HDFS</div><div class="line">hadoop fs -copyToLocal   /user/hadoop/ccc/staff.csv /opt/staff_download.csv 	##檔案下載到/opt</div><div class="line">hadoop fs -moveFromLocal</div><div class="line">hadoop fs -moveToLocal</div><div class="line"></div><div class="line"></div><div class="line">hadoop fsck /user/hadoop/data/staff.csv -files -blocks -locations</div><div class="line">hadoop fsck -blockId blk_&lt;id&gt;</div><div class="line"></div><div class="line">hadoop dfsadmin -safemode enter	##進入安全模式</div><div class="line">hadoop dfsadmin -safemode leave ##離開安全模式</div><div class="line">hadoop dfsadmin -safemode get   ##取得目前狀態</div><div class="line">hadoop dfsadmin -safemode wait  </div><div class="line"></div><div class="line">hadoop dfsadmin -report</div><div class="line">hadoop dfsadmin -refreshNodes</div><div class="line">hadoop dfsadmin -printTopology</div><div class="line"></div><div class="line">hadoop namenode -format		##格式化namenode,在HDFS系統上的資料會全部刪除</div></pre></td></tr></table></figure>
</blockquote>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class
    
    </summary>
    
      <category term="hadoop" scheme="http://yoursite.com/categories/hadoop/"/>
    
    
  </entry>
  
  <entry>
    <title>Hadoop Cluster相關環境建置筆記(持續修正中......)</title>
    <link href="http://yoursite.com/2017/01/08/%5BInstall%5DBigData/"/>
    <id>http://yoursite.com/2017/01/08/[Install]BigData/</id>
    <published>2017-01-08T10:00:00.000Z</published>
    <updated>2017-03-10T02:34:23.489Z</updated>
    
    <content type="html"><![CDATA[<h3 id="安裝前準備"><a href="#安裝前準備" class="headerlink" title="安裝前準備"></a>安裝前準備</h3><h4 id="停止iptables服務"><a href="#停止iptables服務" class="headerlink" title="停止iptables服務"></a>停止iptables服務</h4><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">## 先使用root登入Linux OS</div><div class="line">service iptables stop  #停止iptables服務</div><div class="line">vi /etc/rc.local</div><div class="line">service iptables stop  #停止iptables服務,存檔後離開</div></pre></td></tr></table></figure>
</blockquote>
<h4 id="新增hadoop-User-並賦予hadoop-root的權限"><a href="#新增hadoop-User-並賦予hadoop-root的權限" class="headerlink" title="新增hadoop User,並賦予hadoop root的權限"></a>新增hadoop User,並賦予hadoop root的權限</h4><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">adduser hadoop</div><div class="line">passwd  hadoop</div><div class="line"></div><div class="line">visudo</div><div class="line">hadoop	ALL=(ALL) ALL  #加入這一行,存檔後離開</div><div class="line">(以上步驟每台電腦都要做)</div></pre></td></tr></table></figure>
</blockquote>
<h4 id="進行SSH相關的設定-透過ssh做無密碼連線測試"><a href="#進行SSH相關的設定-透過ssh做無密碼連線測試" class="headerlink" title="進行SSH相關的設定,透過ssh做無密碼連線測試"></a>進行SSH相關的設定,透過ssh做無密碼連線測試</h4><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">su - hadoop</div><div class="line">ssh-keygen</div><div class="line">ssh-copy-id hadoop@hadoop-master  ##別忘記自己也要copy</div><div class="line">ssh-copy-id hadoop@hadoop-slave1  ##有幾台datanode就要做幾次</div><div class="line">ssh-copy-id hadoop@hadoop-slave2  ##有幾台datanode就要做幾次</div><div class="line"></div><div class="line">##ssh連線測試</div><div class="line">ssh hadoop-master</div><div class="line">ssh hadoop-slave1</div></pre></td></tr></table></figure>
</blockquote>
<h4 id="系統時間同步"><a href="#系統時間同步" class="headerlink" title="系統時間同步"></a>系統時間同步</h4><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo date [MMddhhmm.SS];hwclocl -w</div></pre></td></tr></table></figure>
</blockquote>
<h4 id="建立安裝目錄"><a href="#建立安裝目錄" class="headerlink" title="建立安裝目錄"></a>建立安裝目錄</h4><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">sudo mkdir -p /bgdt/install_src</div><div class="line">sudo mkdir -p /bgdt/java</div><div class="line">sudo chown -R hadoop:hadoop /bgdt</div></pre></td></tr></table></figure>
</blockquote>
<h4 id="將相關的安裝檔案上傳到-hadoop-master-bget-install-src目錄下"><a href="#將相關的安裝檔案上傳到-hadoop-master-bget-install-src目錄下" class="headerlink" title="將相關的安裝檔案上傳到 hadoop-master /bget/install_src目錄下"></a>將相關的安裝檔案上傳到 hadoop-master /bget/install_src目錄下</h4><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">使用WinSCP上傳比較方便</div><div class="line">jdk-8u101-linux-x64.tar.gz</div><div class="line">hadoop-2.7.2.tar.gz</div><div class="line">spark-2.0.0-bin-hadoop2.7.tgz</div><div class="line">apache-hive-2.1.0-bin.tar.gz</div><div class="line">apache-hive-2.1.0-src.tar.gz</div><div class="line">Anaconda3-4.2.0-Linux-x86_64.sh</div><div class="line">oozie-4.3.0-distro.tar.gz</div><div class="line">mysql-connector-java-5.1.39-bin.jar</div><div class="line">ext-2.2.zip</div></pre></td></tr></table></figure>
</blockquote>
<h4 id="安裝JDK"><a href="#安裝JDK" class="headerlink" title="安裝JDK"></a>安裝JDK</h4><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">tar -zxvf /bgdt/jdk-8u101-linux-x64.tar.gz -C /bgdt/java</div><div class="line"></div><div class="line">##修改 ~/.bashrc</div><div class="line">vi ~/.bshrc</div><div class="line">加入以下兩行</div><div class="line">export JAVA_HOME=/usr/local/jdk1.8.0_101</div><div class="line">export PATH=$JAVA_HOME/bin:$PATH</div><div class="line"></div><div class="line">source ~/.bashrc</div><div class="line">java -version</div><div class="line">(以上步驟在每台Datanode上也需要安裝喔!!)</div></pre></td></tr></table></figure>
</blockquote>
<h3 id="Hadoop-Cluster安裝-2-7-2-每台電腦皆要安裝"><a href="#Hadoop-Cluster安裝-2-7-2-每台電腦皆要安裝" class="headerlink" title="Hadoop Cluster安裝(2.7.2),每台電腦皆要安裝"></a>Hadoop Cluster安裝(2.7.2),每台電腦皆要安裝</h3><h4 id="解壓縮並設定相關環境變數"><a href="#解壓縮並設定相關環境變數" class="headerlink" title="解壓縮並設定相關環境變數"></a>解壓縮並設定相關環境變數</h4><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">[hadoop@hadoop-master]tar -zxvf /bgdt/hadoop-2.7.2.tar.gz -C /bgdt</div><div class="line">##修改 ~/.bashrc</div><div class="line">vi ~/.bshrc</div><div class="line">加入以下變數</div><div class="line">export HADOOP_HOME=/bgdt/hadoop-2.7.2</div><div class="line">export HADOOP_CONF_DIR=/bgdt/hadoop-2.7.2/etc/hadoop</div><div class="line"></div><div class="line">export CLASSPATH=$CLASSPATH:$HADOOP_HOME/lib/*:.</div><div class="line">export CLASSPATH=$CLASSPATH:$HADOOP_HOME/share/hadoop/common/*:.</div><div class="line"></div><div class="line">export PATH=$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH</div><div class="line"></div><div class="line">source ~/.bashrc</div><div class="line">java -version</div></pre></td></tr></table></figure>
</blockquote>
<h4 id="修改設定檔"><a href="#修改設定檔" class="headerlink" title="修改設定檔"></a>修改設定檔</h4><h5 id="修改設定檔-bgdt-hadoop-2-7-2-etc-hadoop-core-site-xml"><a href="#修改設定檔-bgdt-hadoop-2-7-2-etc-hadoop-core-site-xml" class="headerlink" title="修改設定檔(/bgdt/hadoop-2.7.2/etc/hadoop/core-site.xml)"></a>修改設定檔(/bgdt/hadoop-2.7.2/etc/hadoop/core-site.xml)</h5><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">&lt;configuration&gt;</div><div class="line">&lt;property&gt;</div><div class="line">   &lt;name&gt;fs.defaultFS&lt;/name&gt;</div><div class="line">   &lt;value&gt;hdfs://hadoop-master:8020&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">   &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</div><div class="line">   &lt;value&gt;file:/bgdt/hadoop-2.7.2/tmp&lt;/value&gt;           </div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">   &lt;name&gt;hadoop.proxyuser.hadoop.hosts&lt;/name&gt;</div><div class="line">   &lt;value&gt;*&lt;/value&gt;    </div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">   &lt;name&gt;hadoop.proxyuser.hadoop.groups&lt;/name&gt;</div><div class="line">   &lt;value&gt;*&lt;/value&gt;    </div><div class="line">&lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
</blockquote>
<h5 id="修改設定檔-bgdt-hadoop-2-7-2-etc-hadoop-hdfs-site-xml"><a href="#修改設定檔-bgdt-hadoop-2-7-2-etc-hadoop-hdfs-site-xml" class="headerlink" title="修改設定檔(/bgdt/hadoop-2.7.2/etc/hadoop/hdfs-site.xml)"></a>修改設定檔(/bgdt/hadoop-2.7.2/etc/hadoop/hdfs-site.xml)</h5><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">&lt;configuration&gt;</div><div class="line">  &lt;property&gt;</div><div class="line">   &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;</div><div class="line">   &lt;value&gt;hadoop-master:50070&lt;/value&gt;</div><div class="line">  &lt;/property&gt;</div><div class="line">  &lt;property&gt;</div><div class="line">   &lt;name&gt;dfs.replication&lt;/name&gt;</div><div class="line">   &lt;value&gt;2&lt;/value&gt;</div><div class="line">  &lt;/property&gt;</div><div class="line">  &lt;property&gt;</div><div class="line">   &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;</div><div class="line">   &lt;value&gt;file:/bgdt/hadoop-2.7.2/tmp/dfs/name&lt;/value&gt;</div><div class="line">  &lt;/property&gt;</div><div class="line">  &lt;property&gt;</div><div class="line">   &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;</div><div class="line">   &lt;value&gt;file:/bgdt/hadoop-2.7.2/tmp/dfs/data&lt;/value&gt;</div><div class="line">  &lt;/property&gt;</div><div class="line">  &lt;property&gt;</div><div class="line">   &lt;name&gt;dfs.block.size&lt;/name&gt;</div><div class="line">   &lt;value&gt;64M&lt;/value&gt;   </div><div class="line">  &lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
</blockquote>
<h5 id="修改設定檔-bgdt-hadoop-2-7-2-etc-hadoop-mapred-site-xml"><a href="#修改設定檔-bgdt-hadoop-2-7-2-etc-hadoop-mapred-site-xml" class="headerlink" title="修改設定檔(/bgdt/hadoop-2.7.2/etc/hadoop/mapred-site.xml)"></a>修改設定檔(/bgdt/hadoop-2.7.2/etc/hadoop/mapred-site.xml)</h5><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">&lt;configuration&gt;</div><div class="line">  &lt;property&gt;</div><div class="line">   &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</div><div class="line">   &lt;value&gt;yarn&lt;/value&gt;</div><div class="line">  &lt;/property&gt;</div><div class="line">  &lt;property&gt;</div><div class="line">   &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;</div><div class="line">   &lt;value&gt;hadoop-master:10020&lt;/value&gt;</div><div class="line">  &lt;/property&gt;</div><div class="line">  &lt;property&gt;</div><div class="line">   &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;</div><div class="line">   &lt;value&gt;hadoop-master:19888&lt;/value&gt;</div><div class="line">  &lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
</blockquote>
<h5 id="修改設定檔-bgdt-hadoop-2-7-2-etc-hadoop-yarn-site-xml"><a href="#修改設定檔-bgdt-hadoop-2-7-2-etc-hadoop-yarn-site-xml" class="headerlink" title="修改設定檔(/bgdt/hadoop-2.7.2/etc/hadoop/yarn-site.xml)"></a>修改設定檔(/bgdt/hadoop-2.7.2/etc/hadoop/yarn-site.xml)</h5><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">&lt;configuration&gt;</div><div class="line">   &lt;property&gt;</div><div class="line">    &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;</div><div class="line">    &lt;value&gt;hadoop-master&lt;/value&gt;</div><div class="line">  &lt;/property&gt;</div><div class="line">   &lt;property&gt;</div><div class="line">    &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</div><div class="line">    &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</div><div class="line">  &lt;/property&gt;</div><div class="line">  &lt;property&gt;</div><div class="line">    &lt;name&gt;yarn.log.server.url&lt;/name&gt;</div><div class="line">    &lt;value&gt;http://hadoop-master:19888/jobhistory/logs&lt;/value&gt;</div><div class="line">  &lt;/property&gt;  </div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
</blockquote>
<h5 id="修改設定檔-bgdt-hadoop-2-7-2-etc-hadoop-slaves"><a href="#修改設定檔-bgdt-hadoop-2-7-2-etc-hadoop-slaves" class="headerlink" title="修改設定檔(/bgdt/hadoop-2.7.2/etc/hadoop/slaves)"></a>修改設定檔(/bgdt/hadoop-2.7.2/etc/hadoop/slaves)</h5><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">hadoop-slave1</div><div class="line">hadoop-slave2</div></pre></td></tr></table></figure>
</blockquote>
<h5 id="修改設定檔-bgdt-hadoop-2-7-2-etc-hadoop-capacity-scheduler-xml"><a href="#修改設定檔-bgdt-hadoop-2-7-2-etc-hadoop-capacity-scheduler-xml" class="headerlink" title="修改設定檔(/bgdt/hadoop-2.7.2/etc/hadoop/capacity-scheduler.xml)"></a>修改設定檔(/bgdt/hadoop-2.7.2/etc/hadoop/capacity-scheduler.xml)</h5><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">僅修改以下屬性值(0.1--&gt;0.5)</div><div class="line">.......</div><div class="line">&lt;property&gt;</div><div class="line"> &lt;name&gt;yarn.scheduler.capacity.maximum-am-resource-percent&lt;/name&gt;</div><div class="line"> &lt;value&gt;0.5&lt;/value&gt; </div><div class="line">&lt;/property&gt;</div><div class="line">......</div></pre></td></tr></table></figure>
</blockquote>
<h4 id="將檔案分送到其他Datanode"><a href="#將檔案分送到其他Datanode" class="headerlink" title="將檔案分送到其他Datanode"></a>將檔案分送到其他Datanode</h4><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">##將目錄壓縮</div><div class="line">tar -zcf /bgdt/hadoop.master.tar.gz /bgdt/hadoop-2.7.2</div><div class="line">scp /bgdt/hadoop.master.tar.gz hadoop-slave1:/bgdt/install_src</div><div class="line">scp /bgdt/hadoop.master.tar.gz hadoop-slave2:/bgdt/install_src</div><div class="line"></div><div class="line">##各個Datanode將Hadoop解壓縮至/bgdt,解完後設定相關Haoop變數如第一大項</div></pre></td></tr></table></figure>
</blockquote>
<h4 id="格式化HDFS系統"><a href="#格式化HDFS系統" class="headerlink" title="格式化HDFS系統"></a>格式化HDFS系統</h4><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">hadoop namenode -format</div><div class="line">hadoop dfsadmin -report</div></pre></td></tr></table></figure>
</blockquote>
<h4 id="啟動dfs與yarn"><a href="#啟動dfs與yarn" class="headerlink" title="啟動dfs與yarn"></a>啟動dfs與yarn</h4><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">start-dfs.sh</div><div class="line">start-yarn.sh</div></pre></td></tr></table></figure>
</blockquote>
<h4 id="單台Datanode啟動程式"><a href="#單台Datanode啟動程式" class="headerlink" title="單台Datanode啟動程式"></a>單台Datanode啟動程式</h4><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">ssh dna1</div><div class="line">/bgdt/hadoop-2.7.2/sbin/hadoop-daemon.sh start datanode</div><div class="line">/bgdt/hadoop-2.7.2/sbin/yarn-daemon.sh start nodemanager</div></pre></td></tr></table></figure>
</blockquote>
<h4 id="HDFS-WebUI-hadoop-master-50070"><a href="#HDFS-WebUI-hadoop-master-50070" class="headerlink" title="HDFS WebUI (hadoop-master:50070)"></a>HDFS WebUI (hadoop-master:50070)</h4><p><img src="/images/dfs_2.jpg" alt=""></p>
<h4 id="yarn-WebUI-hadoop-master-8088"><a href="#yarn-WebUI-hadoop-master-8088" class="headerlink" title="yarn WebUI (hadoop-master:8088)"></a>yarn WebUI (hadoop-master:8088)</h4><p><img src="/images/yarn_start_success.jpg" alt=""></p>
<h3 id="Spark安裝-2-0-0-僅安裝於NameNode"><a href="#Spark安裝-2-0-0-僅安裝於NameNode" class="headerlink" title="Spark安裝(2.0.0),僅安裝於NameNode"></a>Spark安裝(2.0.0),僅安裝於NameNode</h3><h4 id="Download-spark-2-0-0安裝程式"><a href="#Download-spark-2-0-0安裝程式" class="headerlink" title="Download spark 2.0.0安裝程式"></a><a href="https://http://spark.apache.org/downloads.html" target="_blank" rel="external">Download spark 2.0.0安裝程式</a></h4><p><img src="/images/spark_1.jpg" alt=""><br> 下載後會產生一個 “spark-2.0.0-bin-hadoop2.7.tgz”檔案<br> 或使用wget下載,下載前請先確定是否可以連網路囉!!</p>
<blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">wget -P \</div><div class="line">/bgdt/install_src http://archive.apache.org/dist/spark/spark-2.0.0/spark-2.0.0-bin-hadoop2.7.tgz</div></pre></td></tr></table></figure>
</blockquote>
<h4 id="解壓縮下載檔案"><a href="#解壓縮下載檔案" class="headerlink" title="解壓縮下載檔案"></a>解壓縮下載檔案</h4><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">tar -zxvf /bgdt/install_src/spark-2.0.0-bin-hadoop2.7.tgz -C /bgdt</div><div class="line">mv /bgdt/spark-2.0.0-bin-hadoop2.7 /bgdt/spark-2.0.0	##目錄名稱太長了,所以把目錄名稱改短</div></pre></td></tr></table></figure>
</blockquote>
<h4 id="修改-bashrc"><a href="#修改-bashrc" class="headerlink" title="修改~/.bashrc"></a>修改~/.bashrc</h4><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">export SPARK_HOME=/bgdt/spark-2.0.0</div><div class="line"></div><div class="line">將檔案儲存後,記得下source,讓設定生效</div><div class="line">source ~/.bashrc</div></pre></td></tr></table></figure>
</blockquote>
<h4 id="測試-spark-shell"><a href="#測試-spark-shell" class="headerlink" title="測試(spark-shell)"></a>測試(spark-shell)</h4><h5 id="進入spark-shell-CLI"><a href="#進入spark-shell-CLI" class="headerlink" title="進入spark-shell CLI"></a>進入spark-shell CLI</h5><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">##進入spark-shell</div><div class="line">/bgdt/spark-2.0.0/bin/sparl-shell</div><div class="line">......</div><div class="line">......</div><div class="line">scala&gt;</div></pre></td></tr></table></figure>
</blockquote>
<h5 id="Spark-Scala-Shell-Test"><a href="#Spark-Scala-Shell-Test" class="headerlink" title="Spark Scala Shell Test"></a>Spark Scala Shell Test</h5><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">[CTRL+l] &lt;--清除shell畫面</div><div class="line">scala&gt;sc</div><div class="line">scala&gt;spark</div></pre></td></tr></table></figure>
</blockquote>
<h5 id="Spark-Example-for-Scala-建立檔案內容並上傳至HDFS"><a href="#Spark-Example-for-Scala-建立檔案內容並上傳至HDFS" class="headerlink" title="Spark Example for Scala-建立檔案內容並上傳至HDFS"></a>Spark Example for Scala-建立檔案內容並上傳至HDFS</h5><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">hadoop fs -mkdir -p /user/hadoop/ccc</div><div class="line">echo &quot;1,\&quot;test1\&quot;,10000&quot; &gt;&gt; test1.csv</div><div class="line">echo &quot;2,\&quot;test2\&quot;,20000&quot; &gt;&gt; test1.csv</div><div class="line">echo &quot;3,\&quot;test3\&quot;,30000&quot; &gt;&gt; test1.csv</div><div class="line">echo &quot;4,\&quot;test4\&quot;,40000&quot; &gt;&gt; test1.csv</div><div class="line">echo &quot;5,\&quot;test5\&quot;,50000&quot; &gt;&gt; test1.csv</div><div class="line">cat test1.csv</div><div class="line">hadoop fs -put ~/test1.csv /user/hadoop/ccc</div></pre></td></tr></table></figure>
</blockquote>
<h5 id="Spark-Example-for-Scala-spark-for-scala程式撰寫"><a href="#Spark-Example-for-Scala-spark-for-scala程式撰寫" class="headerlink" title="Spark Example for Scala-spark for scala程式撰寫"></a>Spark Example for Scala-spark for scala程式撰寫</h5><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">scala&gt;val distFile = sc.textFile(&quot;/user/hadoop/ccc/test1.csv&quot;)</div><div class="line">scala&gt;distFile.count()</div><div class="line">scala&gt;distFile.collect()</div></pre></td></tr></table></figure>
</blockquote>
<h5 id="範例執行結果"><a href="#範例執行結果" class="headerlink" title="範例執行結果"></a>範例執行結果</h5><p><img src="/images/spark_shell_3.jpg" alt=""></p>
<h4 id="測試-spark-submit"><a href="#測試-spark-submit" class="headerlink" title="測試(spark-submit)"></a>測試(spark-submit)</h4><h4 id="啟動Spark-History-Server-Port-18080"><a href="#啟動Spark-History-Server-Port-18080" class="headerlink" title="啟動Spark History Server(Port:18080)"></a>啟動Spark History Server(Port:18080)</h4><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">hadoop fs -mkdir -p /tmp/history</div><div class="line">$SPARK_HOME/sbin/start-history-server.sh hdfs://hadoop-master:8020/tmp/history</div></pre></td></tr></table></figure>
</blockquote>
<h4 id="啟動Job-History-Server-Port-19888"><a href="#啟動Job-History-Server-Port-19888" class="headerlink" title="啟動Job History Server(Port:19888)"></a>啟動Job History Server(Port:19888)</h4><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mr-jobhistory-daemon.sh start historyserver</div></pre></td></tr></table></figure>
</blockquote>
<h3 id="MariaDB安裝-10-1-17-僅安裝於NameNode-目前須使用root權限安裝"><a href="#MariaDB安裝-10-1-17-僅安裝於NameNode-目前須使用root權限安裝" class="headerlink" title="MariaDB安裝(10.1.17),僅安裝於NameNode,目前須使用root權限安裝"></a>MariaDB安裝(10.1.17),僅安裝於NameNode,目前須使用root權限安裝</h3><h4 id="下載MariaDB安裝檔-目前最新版本為10-1-20"><a href="#下載MariaDB安裝檔-目前最新版本為10-1-20" class="headerlink" title="下載MariaDB安裝檔(目前最新版本為10.1.20)"></a>下載MariaDB安裝檔(目前最新版本為10.1.20)</h4><p><a href="http://ftp.ubuntu-tw.org/mirror/mariadb//mariadb-10.1.17/bintar-linux-x86_64/mariadb-10.1.17-linux-x86_64.tar.gz" target="_blank" rel="external">Download mariadb-10.1.17-linux-x86_64</a><br><img src="/images/mariadb_install_1.jpg" alt=""></p>
<h4 id="關閉iptables-service"><a href="#關閉iptables-service" class="headerlink" title="關閉iptables service"></a>關閉iptables service</h4><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">先以root權限登入系統並關閉iptables服務</div><div class="line">service iptables stop</div><div class="line">service iptables status</div></pre></td></tr></table></figure>
</blockquote>
<h4 id="建立mysql帳號"><a href="#建立mysql帳號" class="headerlink" title="建立mysql帳號"></a>建立mysql帳號</h4><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">groupadd mysql</div><div class="line">useradd -g mysql mysql</div></pre></td></tr></table></figure>
</blockquote>
<h4 id="安裝MariaDB"><a href="#安裝MariaDB" class="headerlink" title="安裝MariaDB"></a>安裝MariaDB</h4><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">cd /usr/local</div><div class="line">tar -zxvf /bgdt/install_src/mariadb-10.1.17-linux-x86_64.tar.gz -C /usr/local</div><div class="line">ln -s mariadb-10.1.17-linux-x86_64 mysql</div><div class="line">cd mysql</div><div class="line">./scripts/mysql_install_db --user=mysql</div><div class="line">chown -R root .</div><div class="line">chown -R mysql data</div><div class="line">cd /usr/local/mysql</div><div class="line">./bin/mysqld --user=root &amp;</div><div class="line"></div><div class="line">cat &gt; /etc/rc.local &lt;&lt;EOF</div><div class="line">#!/bin/sh -e</div><div class="line">cd $&#123;mariadb_install_dist&#125;/mysql</div><div class="line">./bin/mysqld --user=root &amp;</div><div class="line">exit 0</div><div class="line">EOF</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</blockquote>
<h4 id="啟動MariaDB-修正中…"><a href="#啟動MariaDB-修正中…" class="headerlink" title="啟動MariaDB(修正中…)"></a>啟動MariaDB(修正中…)</h4><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">nohup ./bin/mysqld --user=root &amp;</div><div class="line">./bin/mysqladmin -u root password &apos;!QAZxsw2&apos;  --socket=/var/lib/mysql/mysql.sock </div><div class="line">./bin/mysql -p  --socket=/var/lib/mysql/mysql.sock</div><div class="line">輸入密碼:!QAZxsw2</div></pre></td></tr></table></figure>
</blockquote>
<h4 id="設定權限"><a href="#設定權限" class="headerlink" title="設定權限"></a>設定權限</h4><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">mariadb&gt;create database metastore_db;</div><div class="line">mariadb&gt;SELECT User, Host FROM mysql.user WHERE Host &lt;&gt; &apos;localhost&apos;; </div><div class="line">mariadb&gt;GRANT ALL PRIVILEGES ON *.* TO &apos;root&apos;@&apos;%&apos; IDENTIFIED BY &apos;!QAZxsw2&apos; WITH GRANT OPTION;</div><div class="line">mariadb&gt;FLUSH PRIVILEGES;</div></pre></td></tr></table></figure>
</blockquote>
<h4 id="確認”3306”-Port是否有開啟？並且關閉確認關閉iptables"><a href="#確認”3306”-Port是否有開啟？並且關閉確認關閉iptables" class="headerlink" title="確認”3306” Port是否有開啟？並且關閉確認關閉iptables"></a>確認”3306” Port是否有開啟？並且關閉確認關閉iptables</h4><p><img src="/images/mariadb_install_2.jpg" alt=""></p>
<h3 id="Hive安裝-2-1-1-僅安裝於NameNode"><a href="#Hive安裝-2-1-1-僅安裝於NameNode" class="headerlink" title="Hive安裝(2.1.1),僅安裝於NameNode"></a>Hive安裝(2.1.1),僅安裝於NameNode</h3><h4 id="安裝-設定-啟動-Hive-CLI"><a href="#安裝-設定-啟動-Hive-CLI" class="headerlink" title="安裝/設定/啟動 Hive CLI"></a>安裝/設定/啟動 Hive CLI</h4><h5 id="下載-Hive安裝檔-原始碼"><a href="#下載-Hive安裝檔-原始碼" class="headerlink" title="下載 Hive安裝檔/原始碼"></a>下載 Hive安裝檔/原始碼</h5><p><a href="http://apache.stu.edu.tw/hive/hive-2.1.1/apache-hive-2.1.1-bin.tar.gz" target="_blank" rel="external">Download Hive 安裝檔,apache-hive-2.1.1-bin</a><br><a href="http://apache.stu.edu.tw/hive/hive-2.1.1/apache-hive-2.1.1-src.tar.gz" target="_blank" rel="external">Download Hive 原始碼,apache-hive-2.1.1-src</a><br><img src="/images/hive_install_1.jpg" alt=""></p>
<h5 id="解壓縮檔案"><a href="#解壓縮檔案" class="headerlink" title="解壓縮檔案"></a>解壓縮檔案</h5><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">tar -zxvf /bgdt/install_src/apache-hive-2.1.1-bin.tar.gz -C /bgdt</div><div class="line">mv /bgdt/apache-hive-2.1.1-bin /bgdt/hive-2.1.1</div></pre></td></tr></table></figure>
</blockquote>
<h5 id="修改-bashrc-1"><a href="#修改-bashrc-1" class="headerlink" title="修改~/.bashrc"></a>修改~/.bashrc</h5><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">export HIVE_HOME=/bgdt/hive-2.1.1</div><div class="line">export PATH= $HIVE_HOME\bin:$PATH</div><div class="line">儲存檔案</div><div class="line"></div><div class="line">source ~/.bashrc</div></pre></td></tr></table></figure>
</blockquote>
<h5 id="將mysql-connector-java-5-1-39-bin-jar-copy-to-bgdt-hive-2-1-1-lib目錄下"><a href="#將mysql-connector-java-5-1-39-bin-jar-copy-to-bgdt-hive-2-1-1-lib目錄下" class="headerlink" title="將mysql-connector-java-5.1.39-bin.jar copy to /bgdt/hive-2.1.1/lib目錄下"></a>將mysql-connector-java-5.1.39-bin.jar copy to /bgdt/hive-2.1.1/lib目錄下</h5><h5 id="建立Hive-Warehouse"><a href="#建立Hive-Warehouse" class="headerlink" title="建立Hive Warehouse"></a>建立Hive Warehouse</h5><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">hadoop fs -mkdir -p /user/hive/warehouse</div><div class="line">hadoop fs -mkdir -p /tmp/hive</div></pre></td></tr></table></figure>
</blockquote>
<h5 id="Modify-hive-site-xml"><a href="#Modify-hive-site-xml" class="headerlink" title="Modify hive-site.xml"></a>Modify hive-site.xml</h5><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div></pre></td><td class="code"><pre><div class="line">&lt;property&gt;</div><div class="line">    &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;</div><div class="line">    &lt;value&gt;jdbc:mysql://192.168.XXX.XXX:3306/metastore_db&lt;/value&gt;</div><div class="line">    &lt;description&gt;JDBC connect string for a JDBC metastore &lt;/description&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">    &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;</div><div class="line">    &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;</div><div class="line">    &lt;description&gt;Driver class name for a JDBC metastore&lt;/description&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">    &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;</div><div class="line">    &lt;value&gt;root&lt;/value&gt;</div><div class="line">    &lt;description&gt;username to use against metastore database&lt;/description&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">    &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;</div><div class="line">    &lt;value&gt;XXXXXXXXX&lt;/value&gt;</div><div class="line">    &lt;description&gt;password to use against metastore database&lt;/description&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">    &lt;name&gt;hive.exec.scratchdir&lt;/name&gt;</div><div class="line">    &lt;value&gt;/tmp/hive&lt;/value&gt;</div><div class="line">    &lt;description&gt;HDFS root scratch dir for Hive jobs which gets created with write all (733) permission. For each connecting user, an HDFS scratch dir: $&#123;hive.exec.scratchdir&#125;/&amp;lt;username&amp;gt; is created, with $&#123;hive.scratch.dir.permission&#125;.&lt;/description&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">    &lt;name&gt;hive.exec.local.scratchdir&lt;/name&gt;</div><div class="line">    &lt;value&gt;/tmp&lt;/value&gt;</div><div class="line">    &lt;description&gt;Local scratch space for Hive jobs&lt;/description&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">    &lt;name&gt;hive.downloaded.resources.dir&lt;/name&gt;</div><div class="line">    &lt;value&gt;/tmp&lt;/value&gt;</div><div class="line">    &lt;description&gt;Temporary local directory for added resources in the remote file system.&lt;/description&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">    &lt;name&gt;hive.scratch.dir.permission&lt;/name&gt;</div><div class="line">    &lt;value&gt;775&lt;/value&gt;</div><div class="line">    &lt;description&gt;The permission for the user specific scratch directories that get created.&lt;/description&gt;</div><div class="line">&lt;/property&gt;</div></pre></td></tr></table></figure>
</blockquote>
<h5 id="create-metastore-db-相關Table"><a href="#create-metastore-db-相關Table" class="headerlink" title="create metastore_db 相關Table"></a>create metastore_db 相關Table</h5><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">##此動作會在mariadb的metastore_db中建立Hive用到的系統表格(以下動作會將meta資料重建)</div><div class="line">schematool -dbType mysql -initSchema</div></pre></td></tr></table></figure>
</blockquote>
<h5 id="在命令列中執行Hive-CLI"><a href="#在命令列中執行Hive-CLI" class="headerlink" title="在命令列中執行Hive CLI"></a>在命令列中執行Hive CLI</h5><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">hive</div><div class="line">......</div><div class="line">......</div><div class="line">hive&gt;</div></pre></td></tr></table></figure>
</blockquote>
<h6 id="在hive的CLI下建立Database及Table"><a href="#在hive的CLI下建立Database及Table" class="headerlink" title="在hive的CLI下建立Database及Table"></a>在hive的CLI下建立Database及Table</h6><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">hive&gt;create database test1;</div><div class="line">hive&gt;create table test1.staff(id int, name string, salary double) </div><div class="line">hive&gt;row format delimited fields terminated by &apos;,&apos;;</div><div class="line">hive&gt;LOAD DATA INPATH &apos;/user/hadoop/ccc/test1.csv&apos; overwrite into table test1.staff;</div><div class="line">hive&gt;select * from test1.staff;</div></pre></td></tr></table></figure>
</blockquote>
<h6 id="以上命令執行結果"><a href="#以上命令執行結果" class="headerlink" title="以上命令執行結果"></a>以上命令執行結果</h6><p><img src="/images/hive_shell_1.jpg" alt=""></p>
<h4 id="HWI安裝與設定-選裝"><a href="#HWI安裝與設定-選裝" class="headerlink" title="HWI安裝與設定(選裝)"></a>HWI安裝與設定(選裝)</h4><h5 id="將已下載的Hive-Souce-code解壓縮至-bgdt"><a href="#將已下載的Hive-Souce-code解壓縮至-bgdt" class="headerlink" title="將已下載的Hive Souce code解壓縮至/bgdt"></a>將已下載的Hive Souce code解壓縮至/bgdt</h5><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">tar -zxvf /bgdt/install_src/apache-hive-2.1.0-src.tar.gz -C /bgdt</div><div class="line">cd /bgdt/apache-hive-2.1.0-src/hwi</div><div class="line">jar cfM hive-hwi-2.1.0.war -C web .</div><div class="line">cp hive-hwi-2.1.0.war /bgdt/hive-2.1.0/lib/*</div></pre></td></tr></table></figure>
</blockquote>
<h5 id="修改hive-site-xml"><a href="#修改hive-site-xml" class="headerlink" title="修改hive-site.xml"></a>修改hive-site.xml</h5><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">&lt;property&gt;</div><div class="line">    &lt;name&gt;hive.hwi.listen.host&lt;/name&gt;</div><div class="line">    &lt;value&gt;hadoop-master&lt;/value&gt;</div><div class="line">    &lt;description&gt;This is the host address the Hive Web Interface will listen on&lt;/description&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">    &lt;name&gt;hive.hwi.listen.port&lt;/name&gt;</div><div class="line">    &lt;value&gt;9999&lt;/value&gt;</div><div class="line">    &lt;description&gt;This is the port the Hive Web Interface will listen on&lt;/description&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">    &lt;name&gt;hive.hwi.war.file&lt;/name&gt;</div><div class="line">    &lt;value&gt;lib/hive-hwi-2.1.0.war&lt;/value&gt;</div><div class="line">    &lt;description&gt;This sets the path to the HWI war file, relative to $&#123;HIVE_HOME&#125;. &lt;/description&gt;</div><div class="line">&lt;/property&gt;</div></pre></td></tr></table></figure>
</blockquote>
<h5 id="Start-HWI-Service"><a href="#Start-HWI-Service" class="headerlink" title="Start HWI Service"></a>Start HWI Service</h5><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">##HWI啟動Port(9999)</div><div class="line">nohup hive --service hwi &amp;</div><div class="line">netstat -tnl | grep &quot;9999&quot;</div></pre></td></tr></table></figure>
</blockquote>
<h5 id="HWI介面-請連到http-hadoop-master-9999-hwi"><a href="#HWI介面-請連到http-hadoop-master-9999-hwi" class="headerlink" title="HWI介面(請連到http://hadoop-master:9999/hwi)"></a>HWI介面(請連到<a href="http://hadoop-master:9999/hwi" target="_blank" rel="external">http://hadoop-master:9999/hwi</a>)</h5><p><img src="/images/hive_hwi_1.jpg" alt=""></p>
<h4 id="Hive-for-Beeline"><a href="#Hive-for-Beeline" class="headerlink" title="Hive for Beeline"></a>Hive for Beeline</h4><h5 id="Start-hiveserver2"><a href="#Start-hiveserver2" class="headerlink" title="Start hiveserver2"></a>Start hiveserver2</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">##啟動Hive JDBC Port(port:10000)</div><div class="line">nohup hive --service hiveserver2 &amp;</div><div class="line">netstat -tnl | grep &quot;10000&quot;</div></pre></td></tr></table></figure>
<h5 id="使用beeline連線Hive-須連線HiveServer2"><a href="#使用beeline連線Hive-須連線HiveServer2" class="headerlink" title="使用beeline連線Hive(須連線HiveServer2)"></a>使用beeline連線Hive(須連線HiveServer2)</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">beeline</div><div class="line"></div><div class="line">beeline&gt; !connect jdbc:hive2://192.168.11.96:10000/default</div></pre></td></tr></table></figure>
<h3 id="OOZIE安裝-4-3-0-僅安裝於NameNode"><a href="#OOZIE安裝-4-3-0-僅安裝於NameNode" class="headerlink" title="OOZIE安裝(4.3.0),僅安裝於NameNode"></a>OOZIE安裝(4.3.0),僅安裝於NameNode</h3><h4 id="OOZIE安裝與設定"><a href="#OOZIE安裝與設定" class="headerlink" title="OOZIE安裝與設定"></a>OOZIE安裝與設定</h4><h5 id="從Github下載oozie原始碼-編譯oozie-並產生”oozie-4-3-0-tar-gz”檔案"><a href="#從Github下載oozie原始碼-編譯oozie-並產生”oozie-4-3-0-tar-gz”檔案" class="headerlink" title="從Github下載oozie原始碼,編譯oozie,並產生”oozie-4.3.0.tar.gz”檔案"></a>從Github下載oozie原始碼,編譯oozie,並產生”oozie-4.3.0.tar.gz”檔案</h5><h5 id="解壓縮oozie-4-3-0-tar-gz並變更目錄名稱"><a href="#解壓縮oozie-4-3-0-tar-gz並變更目錄名稱" class="headerlink" title="解壓縮oozie-4.3.0.tar.gz並變更目錄名稱"></a>解壓縮oozie-4.3.0.tar.gz並變更目錄名稱</h5><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">sudo tar -zxvf /bgdt/install_src/oozie-4.3.0-distro.tar.gz -C /bgdt</div><div class="line">sudo chown -R hadoop:hadoop /bgdt/oozie-4.3.0</div></pre></td></tr></table></figure>
</blockquote>
<h5 id="搬移相關lib至libext目錄"><a href="#搬移相關lib至libext目錄" class="headerlink" title="搬移相關lib至libext目錄"></a>搬移相關lib至libext目錄</h5><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">mkdir -p /bgdt/oozie-4.3.0/libext</div><div class="line">cp /bgdt/hadoop-2.7.2/share/hadoop/*/*.jar /bgdt/oozie-4.3.0/libext/</div><div class="line">cp /bgdt/hadoop-2.7.2/share/hadoop/*/lib/*.jar /bgdt/oozie-4.3.0/libext/</div><div class="line">rm -rf /bgdt/oozie-4.3.0/libext/jsp-api-2.1.jar</div><div class="line">cp /bgdt/install_src/ext-2.2.zip /bgdt/oozie-4.3.0/libext</div></pre></td></tr></table></figure>
</blockquote>
<h5 id="修改oozie-site-xml"><a href="#修改oozie-site-xml" class="headerlink" title="修改oozie-site.xml"></a>修改oozie-site.xml</h5><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">cat &gt; /bgdt/oozie-4.3.0/conf/oozie-site.xml &lt;&lt;EOF</div><div class="line">&lt;?xml version=&quot;1.0&quot;?&gt;</div><div class="line">&lt;configuration&gt;</div><div class="line">&lt;property&gt;</div><div class="line">  &lt;name&gt;oozie.service.WorkflowAppService.system.libpath&lt;/name&gt;</div><div class="line">  &lt;value&gt;/user/hadoop/share/lib&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">  &lt;name&gt;oozie.service.HadoopAccessorService.hadoop.configurations&lt;/name&gt;</div><div class="line">  &lt;value&gt;*=/bgdt/hadoop-2.7.2/etc/hadoop&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">  &lt;name&gt;oozie.use.system.libpath&lt;/name&gt;</div><div class="line">  &lt;value&gt;true&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">  &lt;name&gt;oozie.service.SparkConfigurationService.spark.configurations&lt;/name&gt;</div><div class="line">  &lt;value&gt;*=/bgdt/spark-2.0.0/conf&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div><div class="line">EOF</div></pre></td></tr></table></figure>
</blockquote>
<h5 id="oozie4-3-0版需要再額外處理oozie-war檔中有hadoop-2-6相關jar檔衝突問題-在執行oozie時-會產生noSuchFile-HAOOP-CLASSPATH的錯誤訊息"><a href="#oozie4-3-0版需要再額外處理oozie-war檔中有hadoop-2-6相關jar檔衝突問題-在執行oozie時-會產生noSuchFile-HAOOP-CLASSPATH的錯誤訊息" class="headerlink" title="oozie4.3.0版需要再額外處理oozie.war檔中有hadoop-2.6相關jar檔衝突問題(在執行oozie時,會產生noSuchFile HAOOP_CLASSPATH的錯誤訊息)"></a>oozie4.3.0版需要再額外處理oozie.war檔中有hadoop-2.6相關jar檔衝突問題(在執行oozie時,會產生noSuchFile HAOOP_CLASSPATH的錯誤訊息)</h5><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">#cd $&#123;install_dist&#125;/oozie-$&#123;OOZIE_VERSION&#125;/oozie</div><div class="line">#/bgdt/java/jdk1.8.0_101/bin/jar -xvf ../oozie.war</div><div class="line">#rm -rf ./WEB-INF/lib/hadoop-*-2.6.0.jar</div><div class="line">#/bgdt/java/jdk1.8.0_101/bin/jar cvf ../oozie.war *.* .</div><div class="line">#rm -rf $&#123;install_dist&#125;/oozie-$&#123;OOZIE_VERSION&#125;/oozie</div></pre></td></tr></table></figure>
</blockquote>
<h5 id="安裝相關Server-createdb"><a href="#安裝相關Server-createdb" class="headerlink" title="安裝相關Server,createdb"></a>安裝相關Server,createdb</h5><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">cd /bgdt/oozie-4.3.0</div><div class="line">./bin/oozie-setup.sh prepare-war</div><div class="line">./bin/oozie-setup.sh db create -run</div><div class="line">./bin/oozied.sh start</div><div class="line">./bin/oozie admin -oozie http://localhost:11000/oozie -status</div></pre></td></tr></table></figure>
</blockquote>
<h5 id="OOZIE-WEB-UI"><a href="#OOZIE-WEB-UI" class="headerlink" title="OOZIE WEB UI:"></a>OOZIE WEB UI:</h5><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">http://hadoop-master:11000/oozie</div></pre></td></tr></table></figure>
</blockquote>
<h4 id="安裝sharelib"><a href="#安裝sharelib" class="headerlink" title="安裝sharelib"></a>安裝sharelib</h4><h5 id="複製相關jar檔"><a href="#複製相關jar檔" class="headerlink" title="複製相關jar檔"></a>複製相關jar檔</h5><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">cd /bgdt/oozie-4.3.0</div><div class="line">tar -zxvf oozie-sharelib-4.3.0-SNAPSHOT.tar.gz</div><div class="line">rm -rf /bgdt/oozie-4.3.0/share/lib/spark</div><div class="line">mkdir -p /bgdt/oozie-4.3.0/share/lib/spark</div><div class="line">cp /bgdt/spark/jars/* /bgdt/oozie-4.3.0/share/lib/spark</div><div class="line">cp oozie-sharelib-oozie-4.3.0-SNAPSHOT.jar  /bgdt/oozie-4.3.0/share/lib/spark</div><div class="line">cp oozie-sharelib-spark-4.3.0-SNAPSHOT.jar  /bgdt/oozie-4.3.0/share/lib/spark</div><div class="line">cp /bgdt/hive-2.1.1/conf/hive-site.xml  /bgdt/oozie-4.3.0/share/lib/spark</div><div class="line">cp /bgdt/install_src/mysql-connector-java-5.1.39-bin.jar /bgdt/oozie-4.3.0/share/lib/spark</div></pre></td></tr></table></figure>
</blockquote>
<h5 id="在HDFS上建立sharelib相關目錄"><a href="#在HDFS上建立sharelib相關目錄" class="headerlink" title="在HDFS上建立sharelib相關目錄"></a>在HDFS上建立sharelib相關目錄</h5><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">hadoop fs -mkdir -p /user/hadoop/share/lib</div><div class="line">hadoop fs -put /bgdt/oozie-4.3.0/share/lib/* /user/hadoop/share/lib</div></pre></td></tr></table></figure>
</blockquote>
<h5 id="重啟oozie"><a href="#重啟oozie" class="headerlink" title="重啟oozie"></a>重啟oozie</h5><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">cd /bgdt/oozie-4.3.0</div><div class="line">./bin/oozied.sh stop</div><div class="line">./bin/oozied.sh start</div></pre></td></tr></table></figure>
</blockquote>
<h4 id="執行oozie提供相關的測試範例"><a href="#執行oozie提供相關的測試範例" class="headerlink" title="執行oozie提供相關的測試範例:"></a>執行oozie提供相關的測試範例:</h4><h5 id="上傳oozie-examples相關設定到-hdfs"><a href="#上傳oozie-examples相關設定到-hdfs" class="headerlink" title="上傳oozie examples相關設定到 hdfs"></a>上傳oozie examples相關設定到 hdfs</h5><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">tar -zxvf oozie-examples.tar.gz</div><div class="line">hadoop fs -mkdir -p /user/hadoop/oozie/examples</div><div class="line">hadoop fs -put -f /bgdt/oozie-4.3.0/examples/* /user/hadoop/oozie/examples</div></pre></td></tr></table></figure>
</blockquote>
<h5 id="修改job-properties"><a href="#修改job-properties" class="headerlink" title="修改job.properties"></a>修改job.properties</h5><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">cd /bgdt/oozie-4.3.0/examples/apps/spark</div><div class="line">vi ./job.properties</div><div class="line"></div><div class="line">##修改以下內容</div><div class="line">nameNode=hdfs://hadoop-master:8020</div><div class="line">jobTracker=hadoop-master:8032</div><div class="line">master=local[*]</div><div class="line">queueName=default</div><div class="line">examplesRoot=oozie/examples</div><div class="line">oozie.use.system.libpath=true</div><div class="line">oozie.wf.application.path=/user/hadoop/oozie/examples/apps/spark</div></pre></td></tr></table></figure>
</blockquote>
<h5 id="執行oozie-example"><a href="#執行oozie-example" class="headerlink" title="執行oozie example"></a>執行oozie example</h5><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">cd /bgdt/oozie-4.3.0</div><div class="line"></div><div class="line">./bin/oozie job </div><div class="line">-oozie http://localhost:11000/oozie \</div><div class="line">-config ./examples/apps/spark/job.properties \</div><div class="line">-run</div></pre></td></tr></table></figure>
</blockquote>
<h5 id="到WebUI觀察執行情形"><a href="#到WebUI觀察執行情形" class="headerlink" title="到WebUI觀察執行情形"></a>到WebUI觀察執行情形</h5><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">http://hadoop-master:8088</div></pre></td></tr></table></figure>
</blockquote>
<h3 id="Anaconda3安裝-4-2-0-選裝-僅安裝於NameNode"><a href="#Anaconda3安裝-4-2-0-選裝-僅安裝於NameNode" class="headerlink" title="Anaconda3安裝(4.2.0),選裝,僅安裝於NameNode"></a>Anaconda3安裝(4.2.0),選裝,僅安裝於NameNode</h3><h4 id="Download-Anaconda3-4-2-0-Linux-x86-sh"><a href="#Download-Anaconda3-4-2-0-Linux-x86-sh" class="headerlink" title="Download Anaconda3-4.2.0-Linux-x86.sh"></a>Download Anaconda3-4.2.0-Linux-x86.sh</h4><p><a href="https://repo.continuum.io/archive/" target="_blank" rel="external">https://repo.continuum.io/archive/</a><br><a href="https://www.continuum.io/downloads" target="_blank" rel="external">https://www.continuum.io/downloads</a></p>
<h4 id="Upload-Anaconda3-4-2-0-Linux-x86-sh-to-Host"><a href="#Upload-Anaconda3-4-2-0-Linux-x86-sh-to-Host" class="headerlink" title="Upload Anaconda3-4.2.0-Linux-x86.sh to Host"></a>Upload Anaconda3-4.2.0-Linux-x86.sh to Host</h4><h4 id="Install-bzip2-if-not-bzip2"><a href="#Install-bzip2-if-not-bzip2" class="headerlink" title="Install bzip2(if not bzip2)"></a>Install bzip2(if not bzip2)</h4><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo yum install bzip2 -y</div></pre></td></tr></table></figure>
</blockquote>
<h4 id="Install-Anaconda3"><a href="#Install-Anaconda3" class="headerlink" title="Install Anaconda3"></a>Install Anaconda3</h4><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">bash /opt/Anaconda3-4.2.0-Linux-x86.sh</div><div class="line">[Enter]</div><div class="line">yes</div><div class="line">/opt/anaconda3</div><div class="line">yes</div></pre></td></tr></table></figure>
</blockquote>
<h4 id="Modify-bashrc"><a href="#Modify-bashrc" class="headerlink" title="Modify ~/.bashrc"></a>Modify ~/.bashrc</h4><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"># added by Anaconda3 4.2.0 installer</div><div class="line">export PATH=&quot;/opt/anaconda3/bin:$PATH&quot;</div></pre></td></tr></table></figure>
</blockquote>
<h4 id="Modify-spark-env-sh"><a href="#Modify-spark-env-sh" class="headerlink" title="Modify spark-env.sh"></a>Modify spark-env.sh</h4><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">vi /usr/local/spark/conf/spark/spark-env.sh</div><div class="line">export PYSPARK_PYTHON=/opt/anaconda3/bin/python3</div><div class="line">export PYSPARK_DRIVER_PYTHON=jupyter</div><div class="line">export PYSPARK_DRIVER_PYTHON_OPTS=</div><div class="line">&quot;notebook --NotebookApp.open_browser=False --NotebookApp.ip=&apos;*&apos; --NotebookApp.port=8880&quot;</div></pre></td></tr></table></figure>
</blockquote>
<h4 id="重新進入Putty後-啟動Hadoop相關服務"><a href="#重新進入Putty後-啟動Hadoop相關服務" class="headerlink" title="重新進入Putty後,啟動Hadoop相關服務"></a>重新進入Putty後,啟動Hadoop相關服務</h4><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">start-dfs.sh  ##start Hadoop</div><div class="line">start-yarn.sh ##start yarn</div><div class="line">nohup /usr/local/spark/bin/pyspark &amp;</div></pre></td></tr></table></figure>
</blockquote>
<h4 id="啟動完成後-打開Web-Browser即可看到Jupyter-Web-UI"><a href="#啟動完成後-打開Web-Browser即可看到Jupyter-Web-UI" class="headerlink" title="啟動完成後,打開Web Browser即可看到Jupyter Web UI"></a>啟動完成後,打開Web Browser即可看到Jupyter Web UI</h4><blockquote>
<p><img src="/images/jupyter_1.jpg" alt=""></p>
</blockquote>
<h4 id="以下編寫測試範例"><a href="#以下編寫測試範例" class="headerlink" title="以下編寫測試範例"></a>以下編寫測試範例</h4><h5 id="進入ipython-Web-UI"><a href="#進入ipython-Web-UI" class="headerlink" title="進入ipython Web UI"></a>進入ipython Web UI</h5><p><img src="/images/jupyter_2.jpg" alt=""></p>
<h5 id="透過SparkContext取得文字檔"><a href="#透過SparkContext取得文字檔" class="headerlink" title="透過SparkContext取得文字檔"></a>透過SparkContext取得文字檔</h5><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">rdd = sc.textFile(&quot;hdfs://XXX.XXX.XXX.XXX:8020/OOO/readme.txt&quot;)</div><div class="line">rdd.count()</div></pre></td></tr></table></figure>
</blockquote>
<h5 id="操作DataFrame範例"><a href="#操作DataFrame範例" class="headerlink" title="操作DataFrame範例"></a>操作DataFrame範例</h5><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">l = [(&apos;Alice&apos;, 1)]</div><div class="line">spark.createDataFrame(l).collect()</div><div class="line">spark.createDataFrame(l, [&apos;name&apos;, &apos;age&apos;]).collect()</div></pre></td></tr></table></figure>
</blockquote>
<h5 id="使用Spark-SQL取得資料"><a href="#使用Spark-SQL取得資料" class="headerlink" title="使用Spark SQL取得資料"></a>使用Spark SQL取得資料</h5><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">ds = spark.sql(&quot;select * from students&quot;)</div><div class="line">ds.take(5)</div></pre></td></tr></table></figure>
</blockquote>
<h3 id="相關參考"><a href="#相關參考" class="headerlink" title="相關參考"></a>相關參考</h3><h4 id="參考文件-Link"><a href="#參考文件-Link" class="headerlink" title="參考文件(Link)"></a>參考文件(Link)</h4><p><a href="http://yenyu-lovelan.blogspot.tw/2015/09/spark-on-ubuntu.html" target="_blank" rel="external">Spark on Ubuntu 離線安裝(第一次就上手)</a><br><a href="http://yenyu-lovelan.blogspot.tw/2015/09/spark-on-ubuntu.html" target="_blank" rel="external">Spark Standalone Cluster 練習</a></p>
<h4 id="Big-Data-use-default-port"><a href="#Big-Data-use-default-port" class="headerlink" title="Big Data use default port"></a>Big Data use default port</h4><ol>
<li><p>Hadoop use port</p>
<blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">8020	&lt;-- HDFS Portocol port(NameNode metadata service)(fs.defaultFS)</div><div class="line">50070	&lt;-- HDFS Web Browser HTTP Port,NameNode WebUI(dfs.http.address)(Web)</div><div class="line">50075	&lt;-- DataNode WebUI to access the status, logs etc(dfs.datanode.http.address)(Web)</div><div class="line">50090 	&lt;-- Secondary NameNode Port(dfs.secondary.http.address)</div><div class="line">50020	&lt;-- The datanode ipc server address and port.(dfs.datanode.ipc.address)</div><div class="line">50010	&lt;-- The datanode server address and port for data transfer.(dfs.datanode.address)</div></pre></td></tr></table></figure>
</blockquote>
</li>
<li><p>Yarn cluster use port</p>
<blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">8088	&lt;-- Yarn-Cluster Web UI Port(yarn.resourcemanager.webapp.address)(web)</div><div class="line">8030	&lt;-- yarn.resourcemanager.scheduler.address</div><div class="line">8031	&lt;-- yarn.resourcemanager.resource-tracker.address</div><div class="line">8032	&lt;-- Yarn resourcemnager port(yarn.resourcemanager.address)(JobTracker port for Hadoop2.X)</div><div class="line">8033	&lt;-- yarn.resourcemanager.admin.address</div><div class="line">8040	&lt;-- Address where the localizer IPC is.(yarn.nodemanager.localizer.address)</div><div class="line">8042	&lt;-- NM Webapp address.(yarn.nodemanager.webapp.address)</div></pre></td></tr></table></figure>
</blockquote>
</li>
<li><p>Hive use port</p>
<blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">10000	&lt;-- Hive Server2 Port(Hive JDBC Use)(ENV Variable HIVE_PORT)</div><div class="line">10002	&lt;-- Hive Server2 Web UI</div></pre></td></tr></table></figure>
</blockquote>
</li>
<li><p>Oozie use port</p>
<blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">11000	&lt;-- OOZIE Web UI Port(OOZIE_HTTP_PORT in oozie_env.sh)(Web)</div><div class="line">11001   &lt;-- The admin port Oozie server runs(OOZIE_ADMIN_PORT in oozie_env.sh)(OOZIE admin Port)</div></pre></td></tr></table></figure>
</blockquote>
</li>
<li><p>Spark use port</p>
<blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">4040 	&lt;-- Spark Web UI(spark)</div><div class="line">18080   &lt;-- Spark History port(Web)</div></pre></td></tr></table></figure>
</blockquote>
</li>
<li><p>MR-Job History use port</p>
<blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">19888   &lt;-- MR Job History port(Web)</div><div class="line">10020	&lt;-- MapReduce JobHistory server address(mapreduce.jobhistory.address)</div><div class="line">10033	&lt;-- The address of the History server admin interface.(mapreduce.jobhistory.admin.address)</div></pre></td></tr></table></figure>
</blockquote>
</li>
</ol>
<h4 id="Hadoop-Cluster相關環境HEAP-SIZE設定"><a href="#Hadoop-Cluster相關環境HEAP-SIZE設定" class="headerlink" title="Hadoop Cluster相關環境HEAP SIZE設定"></a>Hadoop Cluster相關環境HEAP SIZE設定</h4><h5 id="hadoop-env-sh"><a href="#hadoop-env-sh" class="headerlink" title="hadoop-env.sh"></a>hadoop-env.sh</h5><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">export HADOOP_HEAPSIZE=1024                     ##hadoop namenode&amp;datanode heap size(default 1000)</div><div class="line">export HADOOP_JOB_HISTORYSERVER_HEAPSIZE=1024   ##yarn job history heap size(default 1000)</div></pre></td></tr></table></figure>
</blockquote>
<h5 id="yarn-env-sh"><a href="#yarn-env-sh" class="headerlink" title="yarn-env.sh"></a>yarn-env.sh</h5><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">export YARN_RESOURCEMANAGER_HEAPSIZE=1024    ##Resource Manager heap size(default 1000)</div><div class="line">export YARN_NODEMANAGER_HEAPSIZE=512         ##Node Manager heap size(default 1000)</div></pre></td></tr></table></figure>
</blockquote>
<h4 id="Hadoop-Cluster相關環境啟動與停止程序整理"><a href="#Hadoop-Cluster相關環境啟動與停止程序整理" class="headerlink" title="Hadoop Cluster相關環境啟動與停止程序整理"></a>Hadoop Cluster相關環境啟動與停止程序整理</h4><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">Hadoop Cluster相關服務啟動順序</div><div class="line">------------------------------</div><div class="line">start-dfs.sh</div><div class="line">start-yarn.sh</div><div class="line">mr-jobhistory-daemon.sh start historyserver</div><div class="line">/bgdt/spark-2.0.0/sbin/start-history-server.sh</div><div class="line">nohup hive --service hiveserver2 &amp; (使用&quot;netstat -tnl | grep &apos;10000&apos;&quot;驗證10000 port是否有啟動)</div><div class="line">/bgdt/oozie-4.3.0/bin/oozied.sh start</div><div class="line"></div><div class="line">Hadoop Cluster相關服務停止順序</div><div class="line">------------------------------</div><div class="line">/bgdt/oozie-4.3.0/bin/oozied.sh stop</div><div class="line">mr-jobhistory-daemon.sh stop historyserver</div><div class="line">/bgdt/spark-2.0.0/sbin/stop-history-server.sh</div><div class="line">stop-yarn.sh</div><div class="line">stop-dfs.sh</div><div class="line">hiveserver2需要用&quot;kill -9 PID&quot;方式停止,目前沒有停止指令</div></pre></td></tr></table></figure>
</blockquote>
<h4 id="Hadoop-Cluster相關環境啟動程序名稱"><a href="#Hadoop-Cluster相關環境啟動程序名稱" class="headerlink" title="Hadoop Cluster相關環境啟動程序名稱"></a>Hadoop Cluster相關環境啟動程序名稱</h4><p><img src="/images/hadoop-start-process.jpg" alt=""></p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;安裝前準備&quot;&gt;&lt;a href=&quot;#安裝前準備&quot; class=&quot;headerlink&quot; title=&quot;安裝前準備&quot;&gt;&lt;/a&gt;安裝前準備&lt;/h3&gt;&lt;h4 id=&quot;停止iptables服務&quot;&gt;&lt;a href=&quot;#停止iptables服務&quot; class=&quot;headerli
    
    </summary>
    
      <category term="hadoop" scheme="http://yoursite.com/categories/hadoop/"/>
    
    
  </entry>
  
  <entry>
    <title>常用Linux 命令筆記(for Oracle Linux)</title>
    <link href="http://yoursite.com/2016/12/07/%5BLinux%5DLinux/"/>
    <id>http://yoursite.com/2016/12/07/[Linux]Linux/</id>
    <published>2016-12-07T14:05:00.000Z</published>
    <updated>2017-03-10T02:41:02.821Z</updated>
    
    <content type="html"><![CDATA[<h2 id="常用指令"><a href="#常用指令" class="headerlink" title="常用指令"></a>常用指令</h2><h3 id="新增使用者及密碼修改"><a href="#新增使用者及密碼修改" class="headerlink" title="新增使用者及密碼修改"></a>新增使用者及密碼修改</h3><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">[root@hadoop-master]$useradd hadoop</div><div class="line">[root@hadoop-master]$passwd hadoop</div><div class="line">[root@hadoop-master]$visudo #如果須要讓 &quot;hadoop&quot;使用者暫時具有管理者(root)權限的話,須使用此指令編輯檔案</div><div class="line">......</div><div class="line">root    ALL=(ALL) ALL ##在此行後面加入</div><div class="line">......</div><div class="line">hadoop  ALL=(ALL) ALL</div><div class="line">......</div></pre></td></tr></table></figure>
</blockquote>
<h3 id="系統關機或重啟命令-非”Root”使用者-須加入sudo"><a href="#系統關機或重啟命令-非”Root”使用者-須加入sudo" class="headerlink" title="系統關機或重啟命令(非”Root”使用者,須加入sudo)"></a>系統關機或重啟命令(非”Root”使用者,須加入sudo)</h3><blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">[hadoop@hadoop-master ~]$sudo shutdown -h now        ##系統立刻關機 </div><div class="line">[hadoop@hadoop-master ~]$sudo shutdown -r now        ##系統立刻重新開機 </div><div class="line">[hadoop@hadoop-master ~]$sudo shutdown -h 20:30      ##系統在今天的 20:30 分關機 </div><div class="line">[hadoop@hadoop-master ~]$sudo shutdown -h +10        ##系統在 10 分鐘後關機</div><div class="line">[hadoop@hadoop-master ~]$sudo sync;sync;sync;reboot  ##重新開機指令,配合寫入緩衝資料的sync指令動作</div><div class="line">[hadoop@hadoop-master ~]$sudo init 0                 ##關機</div><div class="line">[hadoop@hadoop-master ~]$sudo init 6                 ##重新啟動</div></pre></td></tr></table></figure>
</blockquote>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;常用指令&quot;&gt;&lt;a href=&quot;#常用指令&quot; class=&quot;headerlink&quot; title=&quot;常用指令&quot;&gt;&lt;/a&gt;常用指令&lt;/h2&gt;&lt;h3 id=&quot;新增使用者及密碼修改&quot;&gt;&lt;a href=&quot;#新增使用者及密碼修改&quot; class=&quot;headerlink&quot; titl
    
    </summary>
    
      <category term="Linux" scheme="http://yoursite.com/categories/Linux/"/>
    
    
  </entry>
  
</feed>
