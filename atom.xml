<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Popal&#39;s Blog</title>
  <subtitle>邊做邊學</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2016-12-04T13:07:01.387Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>popal</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Hello World</title>
    <link href="http://yoursite.com/2016/12/13/hello-world/"/>
    <id>http://yoursite.com/2016/12/13/hello-world/</id>
    <published>2016-12-13T08:57:40.212Z</published>
    <updated>2016-12-04T13:07:01.387Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="external">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="external">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="external">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="external">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo new <span class="string">"My New Post"</span></div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="external">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo server</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="external">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo generate</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="external">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo deploy</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="external">Deployment</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>常用Linux 命令筆記(for Oracle Linux)</title>
    <link href="http://yoursite.com/2016/12/07/Linux/"/>
    <id>http://yoursite.com/2016/12/07/Linux/</id>
    <published>2016-12-07T14:05:00.000Z</published>
    <updated>2016-12-07T14:42:59.132Z</updated>
    
    <content type="html"><![CDATA[<h2 id="常用指令"><a href="#常用指令" class="headerlink" title="常用指令"></a>常用指令</h2><h3 id="新增使用者及密碼修改"><a href="#新增使用者及密碼修改" class="headerlink" title="新增使用者及密碼修改"></a>新增使用者及密碼修改</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">[root@hadoop-master]$useradd hadoop</div><div class="line">[root@hadoop-master]$passwd hadoop</div><div class="line">[root@hadoop-master]$visudo #如果須要讓 &quot;hadoop&quot;使用者暫時具有管理者(root)權限的話,須使用此指令編輯檔案</div><div class="line">......</div><div class="line">root    ALL=(ALL) ALL ##在此行後面加入</div><div class="line">......</div><div class="line">hadoop  ALL=(ALL) ALL</div><div class="line">......</div></pre></td></tr></table></figure>
<h3 id="系統關機或重啟命令-非”Root”使用者-須加入sudo"><a href="#系統關機或重啟命令-非”Root”使用者-須加入sudo" class="headerlink" title="系統關機或重啟命令(非”Root”使用者,須加入sudo)"></a>系統關機或重啟命令(非”Root”使用者,須加入sudo)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">[hadoop@hadoop-master ~]$sudo shutdown -h now        ##系統立刻關機 </div><div class="line">[hadoop@hadoop-master ~]$sudo shutdown -r now        ##系統立刻重新開機 </div><div class="line">[hadoop@hadoop-master ~]$sudo shutdown -h 20:30      ##系統在今天的 20:30 分關機 </div><div class="line">[hadoop@hadoop-master ~]$sudo shutdown -h +10        ##系統在 10 分鐘後關機</div><div class="line">[hadoop@hadoop-master ~]$sudo sync;sync;sync;reboot  ##重新開機指令,配合寫入緩衝資料的sync指令動作</div><div class="line">[hadoop@hadoop-master ~]$sudo init 0                 ##關機</div><div class="line">[hadoop@hadoop-master ~]$sudo init 6                 ##重新啟動</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;常用指令&quot;&gt;&lt;a href=&quot;#常用指令&quot; class=&quot;headerlink&quot; title=&quot;常用指令&quot;&gt;&lt;/a&gt;常用指令&lt;/h2&gt;&lt;h3 id=&quot;新增使用者及密碼修改&quot;&gt;&lt;a href=&quot;#新增使用者及密碼修改&quot; class=&quot;headerlink&quot; titl
    
    </summary>
    
      <category term="技術之路" scheme="http://yoursite.com/categories/technology/"/>
    
    
      <category term="命令" scheme="http://yoursite.com/tags/%E5%91%BD%E4%BB%A4/"/>
    
  </entry>
  
  <entry>
    <title>Big Data相關環境建置筆記</title>
    <link href="http://yoursite.com/2016/12/04/BigData/"/>
    <id>http://yoursite.com/2016/12/04/BigData/</id>
    <published>2016-12-04T13:10:28.000Z</published>
    <updated>2017-01-05T10:41:50.143Z</updated>
    
    <content type="html"><![CDATA[<h3 id="安裝前準備-每台Datanode也要做"><a href="#安裝前準備-每台Datanode也要做" class="headerlink" title="安裝前準備(每台Datanode也要做)"></a>安裝前準備(每台Datanode也要做)</h3><ol>
<li>先使用root登入Linux OS<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div></pre></td><td class="code"><pre><div class="line">##停止iptables服務</div><div class="line">[root@hadoop-master]service iptables stop  #停止iptables服務</div><div class="line">[root@hadoop-master]vi /etc/rc.local</div><div class="line">service iptables stop  #停止iptables服務,存檔後離開</div><div class="line"></div><div class="line">##新增hadoop User</div><div class="line">[root@hadoop-master]adduser hadoop</div><div class="line">[root@hadoop-master]passwd  hadoop</div><div class="line">[root@hadoop-master]visudo</div><div class="line">hadoop	ALL=(ALL) ALL  #加入這一行,存檔後離開</div><div class="line">(以上步驟每台電腦都要做)</div><div class="line"></div><div class="line">[root@hadoop-master]su - hadoop</div><div class="line"></div><div class="line">##ssh 設定</div><div class="line">[hadoop@hadoop-master]ssh-keygen</div><div class="line">[hadoop@hadoop-master]ssh-copy-id hadoop@hadoop-master  ##別忘記自己也要copy</div><div class="line">[hadoop@hadoop-master]ssh-copy-id hadoop@hadoop-slave1  ##有幾台datanode就要做幾次</div><div class="line">[hadoop@hadoop-master]ssh-copy-id hadoop@hadoop-slave2  ##有幾台datanode就要做幾次</div><div class="line"></div><div class="line">##ssh連線測試</div><div class="line">[hadoop@hadoop-master]ssh hadoop-master</div><div class="line">[hadoop@hadoop-master]ssh hadoop-slave1</div><div class="line"></div><div class="line">##系統時間同步</div><div class="line">[hadoop@hadoop-master]sudo date [MMddHHmmYYYY];hwclocl -w</div><div class="line">[hadoop@hadoop-slave1]sudo date [MMddHHmmYYYY];hwclocl -w</div><div class="line">[hadoop@hadoop-slave2]sudo date [MMddHHmmYYYY];hwclocl -w</div><div class="line"></div><div class="line">##建立安裝目錄</div><div class="line">[hadoop@hadoop-master]sudo mkdir -p /bgdt/install_src</div><div class="line">[hadoop@hadoop-master]sudo mkdir -p /bgdt/java</div><div class="line">[hadoop@hadoop-master]sudo chown -R hadoop:hadoop /bgdt</div><div class="line"></div><div class="line">##將相關的安裝檔案上傳到 hadoop-master /bget/install_src目錄下</div><div class="line">使用WinSCP上傳比較方便囉!!!</div><div class="line">jdk-8u101-linux-x64.tar.gz</div><div class="line">hadoop-2.7.2.tar.gz</div><div class="line">spark-2.0.0-bin-hadoop2.7.tgz</div><div class="line">apache-hive-2.1.1-bin.tar.gz</div><div class="line">apache-hive-2.1.1-src.tar.gz</div><div class="line">Anaconda3-4.2.0-Linux-x86_64.sh</div><div class="line">oozie-4.3.0-SNAPSHOT-distro.tar.gz</div><div class="line">mysql-connector-java-5.1.39-bin.jar</div></pre></td></tr></table></figure>
</li>
</ol>
<h3 id="JDK1-8安裝"><a href="#JDK1-8安裝" class="headerlink" title="JDK1.8安裝"></a>JDK1.8安裝</h3><ol>
<li>安裝JDK<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">[hadoop@hadoop-master]tar -zxvf /bgdt/jdk-8u101-linux-x64.tar.gz -C /bgdt/java</div><div class="line"></div><div class="line">##修改 ~/.bashrc</div><div class="line">[hadoop@hadoop-master]vi ~/.bshrc</div><div class="line">加入以下兩行</div><div class="line">export JAVA_HOME=/usr/local/jdk1.8.0_101</div><div class="line">export PATH=$JAVA_HOME/bin:$PATH</div><div class="line"></div><div class="line">[hadoop@hadoop-master]source ~/.bashrc</div><div class="line">[hadoop@hadoop-master]java -version</div><div class="line">(以上步驟在每台Datanode上也需要安裝喔!!)</div></pre></td></tr></table></figure>
</li>
</ol>
<h3 id="Hadoop-Cluster安裝-2-7-2"><a href="#Hadoop-Cluster安裝-2-7-2" class="headerlink" title="Hadoop Cluster安裝(2.7.2)"></a>Hadoop Cluster安裝(2.7.2)</h3><ol>
<li><p>解壓縮並設定相關環境變數</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">[hadoop@hadoop-master]tar -zxvf /bgdt/hadoop-2.7.2.tar.gz -C /bgdt</div><div class="line">##修改 ~/.bashrc</div><div class="line">[hadoop@hadoop-master]vi ~/.bshrc</div><div class="line">加入以下變數</div><div class="line">export HADOOP_HOME=/bgdt/hadoop-2.7.2</div><div class="line">export HADOOP_CONF_DIR=/bgdt/hadoop-2.7.2/etc/hadoop</div><div class="line"></div><div class="line">export CLASSPATH=$CLASSPATH:$HADOOP_HOME/lib/*:.</div><div class="line">export CLASSPATH=$CLASSPATH:$HADOOP_HOME/share/hadoop/common/*:.</div><div class="line"></div><div class="line">export PATH=$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH</div><div class="line"></div><div class="line">[hadoop@hadoop-master]source ~/.bashrc</div><div class="line">[hadoop@hadoop-master]java -version</div></pre></td></tr></table></figure>
</li>
<li><p>修改設定檔(/bgdt/hadoop-2.7.2/etc/hadoop/core-site.xml)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">&lt;configuration&gt;</div><div class="line">&lt;property&gt;</div><div class="line">   &lt;name&gt;fs.defaultFS&lt;/name&gt;</div><div class="line">   &lt;value&gt;hdfs://hadoop-master:8020&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">   &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</div><div class="line">   &lt;value&gt;file:/usr/local/hadoop-2.7.2/tmp&lt;/value&gt;           </div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">   &lt;name&gt;hadoop.proxyuser.hadoop.hosts&lt;/name&gt;</div><div class="line">   &lt;value&gt;*&lt;/value&gt;    </div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">   &lt;name&gt;hadoop.proxyuser.hadoop.groups&lt;/name&gt;</div><div class="line">   &lt;value&gt;*&lt;/value&gt;    </div><div class="line">&lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
</li>
<li><p>修改設定檔(/bgdt/hadoop-2.7.2/etc/hadoop/hdfs-site.xml)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">&lt;configuration&gt;</div><div class="line">  &lt;property&gt;</div><div class="line">   &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;</div><div class="line">   &lt;value&gt;hadoop-master:50070&lt;/value&gt;</div><div class="line">  &lt;/property&gt;</div><div class="line">  &lt;property&gt;</div><div class="line">   &lt;name&gt;dfs.replication&lt;/name&gt;</div><div class="line">   &lt;value&gt;2&lt;/value&gt;</div><div class="line">  &lt;/property&gt;</div><div class="line">  &lt;property&gt;</div><div class="line">   &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;</div><div class="line">   &lt;value&gt;file:/bgdt/hadoop-2.7.2/tmp/dfs/name&lt;/value&gt;</div><div class="line">  &lt;/property&gt;</div><div class="line">  &lt;property&gt;</div><div class="line">   &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;</div><div class="line">   &lt;value&gt;file:/bgdt/hadoop-2.7.2/tmp/dfs/data&lt;/value&gt;</div><div class="line">  &lt;/property&gt;</div><div class="line">  &lt;property&gt;</div><div class="line">   &lt;name&gt;dfs.block.size&lt;/name&gt;</div><div class="line">   &lt;value&gt;64M&lt;/value&gt;   </div><div class="line">  &lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
</li>
<li><p>修改設定檔(/bgdt/hadoop-2.7.2/etc/hadoop/mapred-site.xml)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">&lt;configuration&gt;</div><div class="line">  &lt;property&gt;</div><div class="line">   &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</div><div class="line">   &lt;value&gt;yarn&lt;/value&gt;</div><div class="line">  &lt;/property&gt;</div><div class="line">  &lt;property&gt;</div><div class="line">   &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;</div><div class="line">   &lt;value&gt;hadoop-master:10020&lt;/value&gt;</div><div class="line">  &lt;/property&gt;</div><div class="line">  &lt;property&gt;</div><div class="line">   &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;</div><div class="line">   &lt;value&gt;hadoop-master:19888&lt;/value&gt;</div><div class="line">  &lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
</li>
<li><p>修改設定檔(/bgdt/hadoop-2.7.2/etc/hadoop/yarn-site.xml)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">&lt;configuration&gt;</div><div class="line">   &lt;property&gt;</div><div class="line">    &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;</div><div class="line">    &lt;value&gt;hadoop-master&lt;/value&gt;</div><div class="line">  &lt;/property&gt;</div><div class="line">   &lt;property&gt;</div><div class="line">    &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</div><div class="line">    &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</div><div class="line">  &lt;/property&gt;</div><div class="line">  &lt;property&gt;</div><div class="line">    &lt;name&gt;yarn.log.server.url&lt;/name&gt;</div><div class="line">    &lt;value&gt;http://hadoop-master:19888/jobhistory/logs&lt;/value&gt;</div><div class="line">  &lt;/property&gt;  </div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
</li>
<li><p>修改設定檔(/bgdt/hadoop-2.7.2/etc/hadoop/slaves)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">hadoop-slave1</div><div class="line">hadoop-slave2</div></pre></td></tr></table></figure>
</li>
<li><p>將檔案分送到其他Datanode</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">##將目錄壓縮</div><div class="line">[hadoop@hadoop-master]tar -zcf /bgdt/hadoop.master.tar.gz /bgdt/hadoop-2.7.2</div><div class="line">[hadoop@hadoop-master]scp /bgdt/hadoop.master.tar.gz hadoop-slave1:/bgdt/install_src</div><div class="line">[hadoop@hadoop-master]scp /bgdt/hadoop.master.tar.gz hadoop-slave2:/bgdt/install_src</div><div class="line"></div><div class="line">##各個Datanode將Hadoop解壓縮至/bgdt,解完後設定相關Haoop變數如第一大項</div></pre></td></tr></table></figure>
</li>
<li><p>格式化HDFS系統</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">[hadoop@hadoop-master]hadoop namenode -format</div><div class="line">[hadoop@hadoop-master]hadoop dfsadmin -report</div></pre></td></tr></table></figure>
</li>
<li><p>啟動dfs與yarn</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">[hadoop@hadoop-master]start-dfs.sh</div><div class="line">[hadoop@hadoop-master]start-yarn.sh</div></pre></td></tr></table></figure>
</li>
<li><p>HDFS WebUI(因為後來系統從做,所以主機名稱略有不同)Web UI port:50070<br><img src="/images/dfs_2.jpg" alt=""></p>
</li>
</ol>
<h3 id="Spark安裝-2-0-0"><a href="#Spark安裝-2-0-0" class="headerlink" title="Spark安裝(2.0.0)"></a>Spark安裝(2.0.0)</h3><ol>
<li><p><a href="https://http://spark.apache.org/downloads.html" target="_blank" rel="external">Download spark 2.0.0安裝程式</a><br><img src="/images/spark_1.jpg" alt=""><br>下載後會產生一個 “spark-2.0.0-bin-hadoop2.7.tgz”檔案<br>或使用wget下載,下載前請先確定是否可以連網路囉!!</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">wget -P /bgdt/install_src http://archive.apache.org/dist/spark/spark-2.0.0/spark-2.0.0-bin-hadoop2.7.tgz</div></pre></td></tr></table></figure>
</li>
<li><p>解壓縮下載檔案</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">tar -zxvf /bgdt/install_src/spark-2.0.0-bin-hadoop2.7.tgz -C /bgdt</div><div class="line">mv /bgdt/spark-2.0.0-bin-hadoop2.7 /bgdt/spark-2.0.0	##目錄名稱太長了,所以把目錄名稱改短</div></pre></td></tr></table></figure>
</li>
<li><p>修改~/.bashrc</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">export SPARK_HOME=/bgdt/spark-2.0.0</div><div class="line"></div><div class="line">將檔案儲存後,記得下source,讓設定生效</div><div class="line">[hadoop@mna1 ~]$source ~/.bashrc</div></pre></td></tr></table></figure>
</li>
<li><p>測試</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">##進入spark-shell</div><div class="line">[hadoop@mna1 ~]$/bgdt/spark-2.0.0/bin/sparl-shell</div><div class="line">......</div><div class="line">......</div><div class="line">scala&gt;</div></pre></td></tr></table></figure>
</li>
<li><p>spark-shell畫面截圖<br><img src="/images/spark_2.jpg" alt=""></p>
</li>
<li><p>Spark Scala Shell Test</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">[CTRL+l] &lt;--清除shell畫面</div><div class="line">scala&gt;sc</div><div class="line">scala&gt;spark</div></pre></td></tr></table></figure>
</li>
<li><p>Spark Example for Scala-建立檔案內容並上傳至HDFS</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">[hadoop@mna1 ~]$hadoop fs -mkdir -p /user/hadoop/ccc</div><div class="line">[hadoop@mna1 ~]$echo &quot;1,\&quot;test1\&quot;,10000&quot; &gt;&gt; test1.csv</div><div class="line">[hadoop@mna1 ~]$echo &quot;2,\&quot;test2\&quot;,20000&quot; &gt;&gt; test1.csv</div><div class="line">[hadoop@mna1 ~]$echo &quot;3,\&quot;test3\&quot;,30000&quot; &gt;&gt; test1.csv</div><div class="line">[hadoop@mna1 ~]$echo &quot;4,\&quot;test4\&quot;,40000&quot; &gt;&gt; test1.csv</div><div class="line">[hadoop@mna1 ~]$echo &quot;5,\&quot;test5\&quot;,50000&quot; &gt;&gt; test1.csv</div><div class="line">[hadoop@mna1 ~]$cat test1.csv</div><div class="line">[hadoop@mna1 ~]$hadoop fs -put ~/test1.csv /user/hadoop/ccc</div></pre></td></tr></table></figure>
</li>
<li><p>Spark Example for Scala-spark for scala程式撰寫</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">scala&gt;val distFile = sc.textFile(&quot;/user/hadoop/ccc/test1.csv&quot;)</div><div class="line">scala&gt;distFile.count()</div><div class="line">scala&gt;distFile.collect()</div></pre></td></tr></table></figure>
</li>
<li><p>範例執行結果<br><img src="/images/spark_shell_3.jpg" alt=""></p>
</li>
</ol>
<h3 id="MariaDB安裝-10-1-17"><a href="#MariaDB安裝-10-1-17" class="headerlink" title="MariaDB安裝(10.1.17)"></a>MariaDB安裝(10.1.17)</h3><ol>
<li>下載MariaDB安裝檔(目前最新版本為10.1.20)<br><a href="http://ftp.ubuntu-tw.org/mirror/mariadb//mariadb-10.1.17/bintar-linux-x86_64/mariadb-10.1.17-linux-x86_64.tar.gz" target="_blank" rel="external">Download mariadb-10.1.17-linux-x86_64</a><br><img src="/images/mariadb_install_1.jpg" alt=""></li>
<li><p>關閉iptables service</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line">先以root權限登入系統並關閉iptables服務</div><div class="line">[root@mna1 ~]$service iptables stop</div><div class="line">[root@mna1 ~]$service iptables status</div><div class="line"></div><div class="line">建立mysql帳號:</div><div class="line">[root@mna1 ~]$groupadd mysql</div><div class="line">[root@mna1 ~]$useradd -g mysql mysql</div><div class="line"></div><div class="line">安裝MariaDB</div><div class="line">[root@mna1 ~]cd /usr/local</div><div class="line">[root@mna1 local]$tar -zxvf /bgdt/install_src/mariadb-10.1.17-linux-x86_64.tar.gz -C /usr/local</div><div class="line">[root@mna1 local]$ln -s mariadb-10.1.17-linux-x86_64 mysql</div><div class="line">[root@mna1 local]$cd mysql</div><div class="line">[root@mna1 mysql]$./scripts/mysql_install_db --user=mysql</div><div class="line">[root@mna1 mysql]$chown -R root .</div><div class="line">[root@mna1 mysql]$chown -R mysql data</div><div class="line"></div><div class="line">啟動MariaDB</div><div class="line">[root@mna1 mysql]$nohup ./bin/mysqld &amp;</div><div class="line">[root@mna1 mysql]$./bin/mysqladmin -u root password &apos;!QAZxsw2&apos;  --socket=/var/lib/mysql/mysql.sock </div><div class="line">[root@mna1 mysql]$./bin/mysql -p  --socket=/var/lib/mysql/mysql.sock</div><div class="line">輸入密碼:!QAZxsw2</div><div class="line"></div><div class="line">設定權限</div><div class="line">mariadb&gt;create database metastore_db;</div><div class="line">mariadb&gt;SELECT User, Host FROM mysql.user WHERE Host &lt;&gt; &apos;localhost&apos;; </div><div class="line">mariadb&gt;GRANT ALL PRIVILEGES ON *.* TO &apos;root&apos;@&apos;%&apos; IDENTIFIED BY &apos;!QAZxsw2&apos; WITH GRANT OPTION;</div><div class="line">mariadb&gt;FLUSH PRIVILEGES;</div></pre></td></tr></table></figure>
</li>
<li><p>觀察3306 Port是否有開啟</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[root@mna1 ~]$netstat -tnl | grep &quot;3306&quot;</div></pre></td></tr></table></figure>
</li>
<li><p>確認”3306” Port是否有開啟？並且關閉確認關閉iptables<br><img src="/images/mariadb_install_2.jpg" alt=""></p>
</li>
</ol>
<h3 id="Hive安裝-2-1-1"><a href="#Hive安裝-2-1-1" class="headerlink" title="Hive安裝(2.1.1)"></a>Hive安裝(2.1.1)</h3><ol>
<li>下載 Hive安裝檔/原始碼<br><a href="http://apache.stu.edu.tw/hive/hive-2.1.1/apache-hive-2.1.1-bin.tar.gz" target="_blank" rel="external">Download Hive 安裝檔,apache-hive-2.1.1-bin</a><br><a href="http://apache.stu.edu.tw/hive/hive-2.1.1/apache-hive-2.1.1-src.tar.gz" target="_blank" rel="external">Download Hive 原始碼,apache-hive-2.1.1-src</a><br><img src="/images/hive_install_1.jpg" alt=""></li>
<li><p>解壓縮檔案</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">tar -zxvf /bgdt/install_src/apache-hive-2.1.1-bin.tar.gz -C /bgdt</div><div class="line">mv /bgdt/apache-hive-2.1.1-bin /bgdt/hive-2.1.1</div></pre></td></tr></table></figure>
</li>
<li><p>修改~/.bashrc</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">export HIVE_HOME=/bgdt/hive-2.1.1</div><div class="line">export PATH= $HIVE_HOME\bin:$PATH</div><div class="line">儲存檔案</div><div class="line"></div><div class="line">source ~/.bashrc</div></pre></td></tr></table></figure>
</li>
<li><p>將mysql-connector-java-5.1.39-bin.jar copy to /bgdt/hive-2.1.1/lib目錄下</p>
</li>
<li><p>建立Hive Warehouse</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">hadoop fs -mkdir -p /user/hive/warehouse</div><div class="line">hadoop fs -mkdir -p /tmp/hive</div></pre></td></tr></table></figure>
</li>
<li><p>Modify hive-site.xml</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div></pre></td><td class="code"><pre><div class="line">&lt;property&gt;</div><div class="line">    &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;</div><div class="line">    &lt;value&gt;jdbc:mysql://192.168.XXX.XXX:3306/metastore_db&lt;/value&gt;</div><div class="line">    &lt;description&gt;JDBC connect string for a JDBC metastore &lt;/description&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">    &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;</div><div class="line">    &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;</div><div class="line">    &lt;description&gt;Driver class name for a JDBC metastore&lt;/description&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">    &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;</div><div class="line">    &lt;value&gt;root&lt;/value&gt;</div><div class="line">    &lt;description&gt;username to use against metastore database&lt;/description&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">    &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;</div><div class="line">    &lt;value&gt;XXXXXXXXX&lt;/value&gt;</div><div class="line">    &lt;description&gt;password to use against metastore database&lt;/description&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">    &lt;name&gt;hive.exec.scratchdir&lt;/name&gt;</div><div class="line">    &lt;value&gt;/tmp/hive&lt;/value&gt;</div><div class="line">    &lt;description&gt;HDFS root scratch dir for Hive jobs which gets created with write all (733) permission. For each connecting user, an HDFS scratch dir: $&#123;hive.exec.scratchdir&#125;/&amp;lt;username&amp;gt; is created, with $&#123;hive.scratch.dir.permission&#125;.&lt;/description&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">    &lt;name&gt;hive.exec.local.scratchdir&lt;/name&gt;</div><div class="line">    &lt;value&gt;/tmp&lt;/value&gt;</div><div class="line">    &lt;description&gt;Local scratch space for Hive jobs&lt;/description&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">    &lt;name&gt;hive.downloaded.resources.dir&lt;/name&gt;</div><div class="line">    &lt;value&gt;/tmp&lt;/value&gt;</div><div class="line">    &lt;description&gt;Temporary local directory for added resources in the remote file system.&lt;/description&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">    &lt;name&gt;hive.scratch.dir.permission&lt;/name&gt;</div><div class="line">    &lt;value&gt;775&lt;/value&gt;</div><div class="line">    &lt;description&gt;The permission for the user specific scratch directories that get created.&lt;/description&gt;</div><div class="line">&lt;/property&gt;</div></pre></td></tr></table></figure>
</li>
<li><p>第一次建立時</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">##此動作會在mariadb的metastore_db中建立Hive用到的系統表格(以下動作會將meta資料重建)</div><div class="line">[hadoop@mna1 ~]$schematool -dbType mysql -initSchema</div></pre></td></tr></table></figure>
</li>
<li><p>在命令列中執行HiveCLI</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">[hadoop@mna1 ~]$hive</div><div class="line">......</div><div class="line">......</div><div class="line">hive&gt;</div></pre></td></tr></table></figure>
</li>
<li><p>在hive的CLI下建立Database及Table</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">hive&gt;create database test1;</div><div class="line">hive&gt;create table test1.staff(id int, name string, salary double) row format delimited fields terminated by &apos;,&apos;;</div><div class="line">hive&gt;LOAD DATA INPATH &apos;/user/hadoop/ccc/test1.csv&apos; overwrite into table test1.staff;</div><div class="line">hive&gt;select * from test1.staff;</div></pre></td></tr></table></figure>
</li>
<li><p>以上命令執行結果:<br><img src="/images/hive_shell_1.jpg" alt=""></p>
</li>
<li><p>HWI安裝<br>將已下載的Hive Souce code解壓縮至/bgdt</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">[hadoop@mna1 ~]$tar -zxvf /bgdt/install_src/apache-hive-2.1.1-src.tar.gz -C /bgdt</div><div class="line">[hadoop@mna1 ~]$cd /bgdt/apache-hive-2.1.1-src/hwi</div><div class="line">[hadoop@mna1 hwi]$ jar cfM hive-hwi-2.1.1.war -C web .</div><div class="line">[hadoop@mna1 hwi]$cp hive-hwi-2.1.1.war /bgdt/hive-2.1.1/lib/*</div></pre></td></tr></table></figure>
</li>
<li><p>修改hive-site.xml</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">&lt;property&gt;</div><div class="line">    &lt;name&gt;hive.hwi.listen.host&lt;/name&gt;</div><div class="line">    &lt;value&gt;mna1&lt;/value&gt;</div><div class="line">    &lt;description&gt;This is the host address the Hive Web Interface will listen on&lt;/description&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">    &lt;name&gt;hive.hwi.listen.port&lt;/name&gt;</div><div class="line">    &lt;value&gt;9999&lt;/value&gt;</div><div class="line">    &lt;description&gt;This is the port the Hive Web Interface will listen on&lt;/description&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">    &lt;name&gt;hive.hwi.war.file&lt;/name&gt;</div><div class="line">    &lt;value&gt;lib/hive-hwi-2.1.1.war&lt;/value&gt;</div><div class="line">    &lt;description&gt;This sets the path to the HWI war file, relative to $&#123;HIVE_HOME&#125;. &lt;/description&gt;</div><div class="line">&lt;/property&gt;</div></pre></td></tr></table></figure>
</li>
<li><p>Start HWI Service</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">##HWI啟動Port(9999)</div><div class="line">[hadoop@hadoop-master ~]$ nohup hive --service hwi &amp;</div><div class="line">[hadoop@hadoop-master ~]$ netstat -tnl | grep &quot;9999&quot;</div></pre></td></tr></table></figure>
</li>
<li><p>HWI介面(請連到<a href="http://XXX.XXX.XXX.XXX:9999/hwi" target="_blank" rel="external">http://XXX.XXX.XXX.XXX:9999/hwi</a>)<br><img src="/images/hive_hwi_1.jpg" alt=""></p>
</li>
<li><p>Start hiveserver2</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">##啟動Hive JDBC Port(port:10000)</div><div class="line">[hadoop@mna1 ~]$ nohup hive --service hiveserver2 &amp;</div><div class="line">[hadoop@mna1 ~]$ netstat -tnl | grep &quot;10000&quot;</div></pre></td></tr></table></figure>
</li>
<li><p>使用beeline連線Hive(須連線HiveServer2)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">[hadoop@mna1 ~]$ beeline</div><div class="line">beeline&gt; !connect jdbc:hive2://192.168.11.96:10000/default</div></pre></td></tr></table></figure>
</li>
</ol>
<h3 id="OOZIE安裝-4-3-0"><a href="#OOZIE安裝-4-3-0" class="headerlink" title="OOZIE安裝(4.3.0)"></a>OOZIE安裝(4.3.0)</h3><h3 id="Anaconda3安裝-4-2-0"><a href="#Anaconda3安裝-4-2-0" class="headerlink" title="Anaconda3安裝(4.2.0)"></a>Anaconda3安裝(4.2.0)</h3><ol>
<li><p>Download Anaconda3-4.2.0-Linux-x86.sh<br><a href="https://repo.continuum.io/archive/" target="_blank" rel="external">https://repo.continuum.io/archive/</a><br><a href="https://www.continuum.io/downloads" target="_blank" rel="external">https://www.continuum.io/downloads</a></p>
</li>
<li><p>Upload Anaconda3-4.2.0-Linux-x86.sh to Host</p>
</li>
<li><p>Install bzip2(if not bzip2)       </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo yum install bzip2 -y</div></pre></td></tr></table></figure>
</li>
<li><p>Install Anaconda3    </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">bash /opt/Anaconda3-4.2.0-Linux-x86.sh</div><div class="line">&gt;&gt;&gt;[Enter]</div><div class="line">......</div><div class="line">&gt;&gt;&gt;yes</div><div class="line">......</div><div class="line">&gt;&gt;&gt;/opt/anaconda3</div><div class="line">......</div><div class="line">&gt;&gt;&gt;yes</div><div class="line">......</div></pre></td></tr></table></figure>
</li>
<li><p>Modify ~/.bashrc  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"># added by Anaconda3 4.2.0 installer</div><div class="line">export PATH=&quot;/opt/anaconda3/bin:$PATH&quot;</div></pre></td></tr></table></figure>
</li>
<li><p>Modify spark-env.sh  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">vi /usr/local/spark/conf/spark/spark-env.sh</div></pre></td></tr></table></figure>
</li>
<li><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">export PYSPARK_PYTHON=/opt/anaconda3/bin/python3</div><div class="line">export PYSPARK_DRIVER_PYTHON=jupyter</div><div class="line">export PYSPARK_DRIVER_PYTHON_OPTS=&quot;notebook --NotebookApp.open_browser=False --NotebookApp.ip=&apos;*&apos; --NotebookApp.port=8880&quot;</div></pre></td></tr></table></figure>
</li>
<li><p>重新進入Putty後,啟動Hadoop相關服務  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">start-dfs.sh  ##start Hadoop</div><div class="line">start-yarn.sh ##start yarn</div><div class="line">nohup /usr/local/spark/bin/pyspark &amp;</div></pre></td></tr></table></figure>
</li>
<li><p>啟動完成後,打開Web Browser即可看到Jupyter Web UI<br><img src="/images/jupyter_1.jpg" alt=""></p>
</li>
<li><p>以下編寫測試範例:<br><img src="/images/jupyter_2.jpg" alt=""></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">rdd = sc.textFile(&quot;hdfs://XXX.XXX.XXX.XXX:8020/OOO/readme.txt&quot;)</div><div class="line">rdd.count()</div></pre></td></tr></table></figure>
</li>
<li><p>操作DataFrame範例:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">l = [(&apos;Alice&apos;, 1)]</div><div class="line">spark.createDataFrame(l).collect()</div><div class="line">spark.createDataFrame(l, [&apos;name&apos;, &apos;age&apos;]).collect()</div></pre></td></tr></table></figure>
</li>
<li><p>使用Spark SQL取得資料</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">ds = spark.sql(&quot;select * from students&quot;)</div><div class="line">ds.take(5)</div></pre></td></tr></table></figure>
</li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;安裝前準備-每台Datanode也要做&quot;&gt;&lt;a href=&quot;#安裝前準備-每台Datanode也要做&quot; class=&quot;headerlink&quot; title=&quot;安裝前準備(每台Datanode也要做)&quot;&gt;&lt;/a&gt;安裝前準備(每台Datanode也要做)&lt;/h3&gt;&lt;ol
    
    </summary>
    
      <category term="技術之路" scheme="http://yoursite.com/categories/technology/"/>
    
    
      <category term="環境安裝" scheme="http://yoursite.com/tags/%E7%92%B0%E5%A2%83%E5%AE%89%E8%A3%9D/"/>
    
  </entry>
  
</feed>
